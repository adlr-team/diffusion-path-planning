{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "APRB2VcQU5C2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Beste Aydemir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\adlr-uQXv-DS1-py3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from diffuser.utils.config import Config, get_params, get_device_settings\n",
        "import os\n",
        "import collections\n",
        "import numpy as np\n",
        "import pdb\n",
        "from minari import DataCollector, StepDataCallback\n",
        "import wandb\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Fd7E-bLXNI"
      },
      "source": [
        "## Diffuser Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rg9GmmXWStiK"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(\n",
        "        self,\n",
        "        loader,\n",
        "        savepath,\n",
        "        dataset,\n",
        "        horizon,\n",
        "        normalizer,\n",
        "        preprocess_fns,\n",
        "        use_padding,\n",
        "        max_path_length,\n",
        "        renderer,\n",
        "        model,\n",
        "        dim_mults,\n",
        "        device,\n",
        "    ):\n",
        "        self.loader = loader\n",
        "        self.savepath = savepath\n",
        "        self.dataset = dataset\n",
        "        self.horizon = horizon\n",
        "        self.normalizer = normalizer\n",
        "        self.preprocess_fns = preprocess_fns\n",
        "        self.use_padding = use_padding\n",
        "        self.max_path_length = max_path_length\n",
        "        self.renderer = renderer\n",
        "        self.model = model\n",
        "        # self.transition_dim=transition_dim\n",
        "        # self.cond_dim=cond_dim\n",
        "        self.dim_mults = dim_mults\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "args = Args(\n",
        "    loader=\"datasets.sequence.GoalDataset\",\n",
        "    savepath=\"saved/\",\n",
        "    dataset=\"\",\n",
        "    horizon=256,\n",
        "    normalizer=\"LimitsNormalizer\",\n",
        "    preprocess_fns=[\"maze2d_set_terminals\"],\n",
        "    use_padding=True,\n",
        "    max_path_length=280,  #from the dataset description\n",
        "    renderer=\"utils.rendering.FrankaRenderer\",\n",
        "    model=\"models.temporal.TemporalUnet\",\n",
        "    dim_mults=(1, 4, 8),\n",
        "    device=\"cpu\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzUNVoCyS54w",
        "outputId": "8fd0ca8e-cce7-456b-9438-15ca2be74525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:datasets.sequence.GoalDataset\n",
            "[ utils/config ] Imported diffuser.datasets.sequence:GoalDataset\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.datasets.sequence.GoalDataset'>\n",
            "    env: FrankaKitchen-v1\n",
            "    horizon: 256\n",
            "    max_path_length: 280\n",
            "    normalizer: LimitsNormalizer\n",
            "    preprocess_fns: ['maze2d_set_terminals']\n",
            "    use_padding: True\n",
            "\n",
            "[ utils/config ] Saved config to: saved/dataset_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset_config = Config(\n",
        "    args.loader,\n",
        "    savepath=(args.savepath, \"dataset_config.pkl\"),\n",
        "    env=\"FrankaKitchen-v1\",\n",
        "    horizon=args.horizon,\n",
        "    normalizer=args.normalizer,\n",
        "    preprocess_fns=args.preprocess_fns,\n",
        "    use_padding=args.use_padding,\n",
        "    max_path_length=args.max_path_length,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Beste Aydemir\\.minari\\datasets\\kitchen-complete-v1\\data\n",
            "kitchen-complete-v1\n",
            "C:\\Users\\Beste Aydemir\\.minari\\datasets\\pointmaze-medium-v2\\data\n",
            "pointmaze-medium-v2\n",
            "kitchen-complete-v1\n",
            "pointmaze-medium-v2\n"
          ]
        }
      ],
      "source": [
        "from minari import DataCollector, list_local_datasets, load_dataset, delete_dataset\n",
        "for dataset_name in list_local_datasets():\n",
        "    print(dataset_name)\n",
        "    #delete_dataset(dataset_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN1wOeVGTaft",
        "outputId": "1d0e9bfe-1bca-4718-a6e9-03954dd5dbc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the enviornment: FrankaKitchen-v1\n",
            "Name of the enviornment: FrankaKitchen-v1\n",
            "seq\n",
            "Dataset_name:kitchen-complete-v1\n",
            "C:\\Users\\Beste Aydemir\\.minari\\datasets\\kitchen-complete-v1\\data\n",
            "kitchen-complete-v1\n",
            "C:\\Users\\Beste Aydemir\\.minari\\datasets\\pointmaze-medium-v2\\data\n",
            "pointmaze-medium-v2\n",
            "dataset exists!\n",
            "hereepisode\n",
            "19\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "in iter\n",
            "[ datasets/buffer ] Finalized replay buffer | 19 episodes\n",
            "here----------\n",
            "[212 208 222 236 223 223 233 224 236 211 219 221 219 223 236 210 214 216\n",
            " 223]\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "280\n",
            "256\n",
            "24\n",
            "[[  0   0 256]\n",
            " [  0   1 257]\n",
            " [  0   2 258]\n",
            " ...\n",
            " [ 18  21 277]\n",
            " [ 18  22 278]\n",
            " [ 18  23 279]]\n",
            "[ datasets/buffer ] Fields:\n",
            "    achieved_goal: (19, 280, 1)\n",
            "    desired_goal: (19, 280, 1)\n",
            "    observations: (19, 280, 59)\n",
            "    observation: (19, 280, 59)\n",
            "    next_observations: (19, 280, 59)\n",
            "    actions: (19, 280, 9)\n",
            "    terminals: (19, 280, 1)\n",
            "    timeouts: (19, 280, 1)\n",
            "[ datasets/buffer ] Fields:\n",
            "    achieved_goal: (19, 280, 1)\n",
            "    desired_goal: (19, 280, 1)\n",
            "    observations: (19, 280, 59)\n",
            "    observation: (19, 280, 59)\n",
            "    next_observations: (19, 280, 59)\n",
            "    actions: (19, 280, 9)\n",
            "    terminals: (19, 280, 1)\n",
            "    timeouts: (19, 280, 1)\n",
            "    normed_observations: (19, 280, 59)\n",
            "    normed_actions: (19, 280, 9)\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index 0 is out of bounds for axis 0 with size 0",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\diffuser-third-test\\diffuser\\datasets\\sequence.py:96\u001b[0m, in \u001b[0;36mSequenceDataset.__getitem__\u001b[1;34m(self, idx, eps)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx, eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m):\n\u001b[1;32m---> 96\u001b[0m     path_ind, start, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     98\u001b[0m     observations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfields\u001b[38;5;241m.\u001b[39mnormed_observations[path_ind, start:end]\n\u001b[0;32m     99\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfields\u001b[38;5;241m.\u001b[39mnormed_actions[path_ind, start:end]\n",
            "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        }
      ],
      "source": [
        "dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENDornlpjRvY"
      },
      "source": [
        "## Configs for Rendering and the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bme6emjGVS6-",
        "outputId": "847b6b49-3758-4e5a-9e0c-3e3872f65259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:utils.rendering.FrankaRenderer\n",
            "[ utils/config ] Imported diffuser.utils.rendering:FrankaRenderer\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.utils.rendering.FrankaRenderer'>\n",
            "    env: FrankaKitchen-v1\n",
            "\n",
            "[ utils/config ] Saved config to: saved/render_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "render_config = Config(\n",
        "    args.renderer,\n",
        "    savepath=(args.savepath, \"render_config.pkl\"),\n",
        "    env=\"FrankaKitchen-v1\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtDYVRdctm86",
        "outputId": "3c4a10d7-ccde-41d4-f7cf-19404180f063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:models.temporal.TemporalUnet\n",
            "[ utils/config ] Imported diffuser.models.temporal:TemporalUnet\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.models.temporal.TemporalUnet'>\n",
            "    cond_dim: 59\n",
            "    dim_mults: (1, 4, 8)\n",
            "    horizon: 256\n",
            "    transition_dim: 68\n",
            "\n",
            "[ utils/config ] Saved config to: saved/model_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# observation_dim = dataset.observation_dim\n",
        "# action_dim = dataset.action_dim\n",
        "observation_dim = 59\n",
        "action_dim = 9\n",
        "# -----------------------------------------------------------------------------#\n",
        "# ------------------------------ model & trainer ------------------------------#\n",
        "# -----------------------------------------------------------------------------#\n",
        "\n",
        "model_config = Config(\n",
        "    args.model,\n",
        "    savepath=(args.savepath, \"model_config.pkl\"),\n",
        "    horizon=args.horizon,\n",
        "    transition_dim=observation_dim + action_dim,\n",
        "    cond_dim=observation_dim,\n",
        "    dim_mults=args.dim_mults,\n",
        "    device=args.device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLILqE_ZrBdy",
        "outputId": "2a032e3e-bf83-48a1-f186-e1c5a62a5e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the enviornment: FrankaKitchen-v1\n"
          ]
        }
      ],
      "source": [
        "renderer = render_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0362NXnEtqzJ",
        "outputId": "b3be0703-1e9a-4fb4-fba6-bc14a3052215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ models/temporal ] Channel dimensions: [(68, 32), (32, 128), (128, 256)]\n",
            "[(68, 32), (32, 128), (128, 256)]\n"
          ]
        }
      ],
      "source": [
        "model = model_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56UTrirwtof5",
        "outputId": "a0d92bcc-c4f6-41bd-fa4f-54d7887afa4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:models.diffuser.GaussianDiffusion\n",
            "[ utils/config ] Imported diffuser.models.diffuser:GaussianDiffusion\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.models.diffuser.GaussianDiffusion'>\n",
            "    action_dim: 9\n",
            "    action_weight: 1\n",
            "    clip_denoised: True\n",
            "    horizon: 256\n",
            "    loss_discount: 1\n",
            "    loss_type: l2\n",
            "    loss_weights: None\n",
            "    n_timesteps: 256\n",
            "    observation_dim: 59\n",
            "    predict_epsilon: False\n",
            "\n",
            "[ utils/config ] Saved config to: saved/diffusion_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "diffusion_config = Config(\n",
        "    _class=\"models.diffuser.GaussianDiffusion\",\n",
        "    savepath=(args.savepath, \"diffusion_config.pkl\"),\n",
        "    horizon=256,\n",
        "    observation_dim=observation_dim,\n",
        "    action_dim=action_dim,\n",
        "    n_timesteps=256,\n",
        "    loss_type=\"l2\",\n",
        "    clip_denoised=True,\n",
        "    predict_epsilon=False,\n",
        "    # loss weighting\n",
        "    action_weight=1,\n",
        "    loss_weights=None,\n",
        "    loss_discount=1,\n",
        "    device=args.device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qUBUMLX-KX-D"
      },
      "outputs": [],
      "source": [
        "diffuser = diffusion_config(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcJZFQl9jXtn"
      },
      "source": [
        "## Forward pass is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "456"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'GoalDataset' object has no attribute '_data'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241m.\u001b[39mtotal_episodes\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'GoalDataset' object has no attribute '_data'"
          ]
        }
      ],
      "source": [
        "dataset._data.total_episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SnQpWsjKlRQ",
        "outputId": "6c4ce3f1-c507-42e2-e51b-485e83ed51ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ utils/arrays ] Total parameters: 3.70 M\n",
            "         downs.2.0.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.2.1.blocks.0.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.2.1.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         ups.0.0.blocks.0.block.0.weight: 327.68 k | Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block1.blocks.0.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block1.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block2.blocks.0.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block2.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.2.0.blocks.0.block.0.weight: 163.84 k | Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.1.0.blocks.1.block.0.weight: 81.92 k | Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         ... and 138 others accounting for 828.87 k parameters\n",
            "Testing forward... ✓\n"
          ]
        }
      ],
      "source": [
        "from diffuser.utils.arrays import report_parameters, batchify\n",
        "\n",
        "report_parameters(model)\n",
        "\n",
        "print(\"Testing forward...\", end=\" \", flush=True)\n",
        "batch = batchify(dataset[0])\n",
        "loss, _ = diffuser.loss(*batch)\n",
        "loss.backward()\n",
        "print(\"✓\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2zObsfx8uFq"
      },
      "source": [
        "## Using the trainer requires taking care of the 'device' in the folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Ahsw3rhEeF",
        "outputId": "72015822-2ea3-4d8d-df37-76026af74d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[utils/config ] Config: <class 'diffuser.utils.training.Trainer'>\n",
            "    bucket: None\n",
            "    ema_decay: 0.005\n",
            "    gradient_accumulate_every: 2\n",
            "    label_freq: 400\n",
            "    n_reference: 1\n",
            "    n_samples: 1\n",
            "    results_folder: saved/\n",
            "    sample_freq: 20\n",
            "    save_freq: 50\n",
            "    save_parallel: False\n",
            "    train_batch_size: 32\n",
            "    train_lr: 0.0002\n",
            "\n",
            "[ utils/config ] Saved config to: saved/trainer_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from diffuser.utils.training import Trainer\n",
        "\n",
        "trainer_config = Config(\n",
        "    Trainer,\n",
        "    savepath=(args.savepath, \"trainer_config.pkl\"),\n",
        "    train_batch_size=32,\n",
        "    train_lr=2e-4,\n",
        "    gradient_accumulate_every=2,\n",
        "    ema_decay=0.005,\n",
        "    sample_freq=20,\n",
        "    save_freq=50,\n",
        "    label_freq=int(2e4 // 50),\n",
        "    save_parallel=False,\n",
        "    results_folder=args.savepath,\n",
        "    bucket=None,\n",
        "    n_reference=1,\n",
        "    n_samples=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KcB-OnzvkFgn"
      },
      "outputs": [],
      "source": [
        "trainer = trainer_config(diffuser, dataset, renderer, device = \"cpu\", name=\"franka\")\n",
        "\n",
        "use_wandb = False\n",
        "\n",
        "current_time = datetime.now().strftime(\"%d_%m_%Y-%H-%M\")\n",
        "\n",
        "if use_wandb:\n",
        "    run = wandb.init(\n",
        "        config=trainer_config.to_dict(),\n",
        "        project=\"Experiment-1\",\n",
        "        name=f\"Name-1_{current_time}\",\n",
        "        group=\"Group-Name\",\n",
        "        job_type=\"training\",\n",
        "        reinit=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRJlcy_WKXdq"
      },
      "source": [
        "# Training process inlcluding rendering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "IaDt0qR3kczo",
        "outputId": "1ac1ee61-695b-4017-cd62-41bf7449b7b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 / 2 | saved/\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "Can't pickle local object 'compose.<locals>._fn'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m#wandb.log({\"Epoch\": i})\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39msavepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_train_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#wandb.finish()\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\diffuser-third-test\\diffuser\\utils\\training.py:138\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, n_train_steps)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_train_steps):\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m#wandb.log({\"Training_steps\": step})\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_accumulate_every):\n\u001b[1;32m--> 138\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m         batch \u001b[38;5;241m=\u001b[39m batch_to_device(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    142\u001b[0m         loss, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mloss(\u001b[38;5;241m*\u001b[39mbatch)\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\diffuser-third-test\\diffuser\\utils\\training.py:19\u001b[0m, in \u001b[0;36mcycle\u001b[1;34m(dl)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcycle\u001b[39m(dl):\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 19\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dl:\n\u001b[0;32m     20\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\adlr-uQXv-DS1-py3.10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:439\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\adlr-uQXv-DS1-py3.10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:387\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\adlr-uQXv-DS1-py3.10\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1040\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1033\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1040\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mAttributeError\u001b[0m: Can't pickle local object 'compose.<locals>._fn'"
          ]
        }
      ],
      "source": [
        "# n_epochs = int(args.n_train_steps // args.n_steps_per_epoch)\n",
        "\n",
        "\n",
        "n_epochs = 2\n",
        "for i in range(n_epochs):\n",
        "    #wandb.log({\"Epoch\": i})\n",
        "    print(f\"Epoch {i} / {n_epochs} | {args.savepath}\")\n",
        "    trainer.train(n_train_steps=1000)\n",
        "#wandb.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh7nFzc5jxhB"
      },
      "source": [
        "## Random Test (don't run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from minari import DataCollector, list_local_datasets, load_dataset, delete_dataset\n",
        "for dataset_name in list_local_datasets():\n",
        "    print(dataset_name)\n",
        "    delete_dataset(dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import minari\n",
        "ddss = minari.download_dataset(\"pointmaze-medium-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = load_dataset(\"pointmaze-medium-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data._data.total_episodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "data[0].observations[\"observation\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make(\n",
        "        \"PointMaze_Medium-v3\", continuing_task=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "({'observation': array([0.59587286, 1.58655485, 0.        , 0.        ]),\n",
              "  'achieved_goal': array([0.59587286, 1.58655485]),\n",
              "  'desired_goal': array([-2.37061747, -0.27548277])},\n",
              " {'success': False})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.59587286, 1.58655485])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env.unwrapped.point_env.init_qpos[:2] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "Qb0DuGNZQMbE",
        "outputId": "2dbcd2a9-9641-4daa-92bb-956bc8a03754"
      },
      "outputs": [],
      "source": [
        "print(len(dataset))\n",
        "for i in range(40):\n",
        "    print(dataset[i].observations[\"observation\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "vugWLtYdZedT",
        "outputId": "12030896-dac2-4e04-f7c9-751cf3f9d8b1"
      },
      "outputs": [],
      "source": [
        "reshaped = {}\n",
        "for key, val in dataset.items():\n",
        "    dim = val.shape[-1]\n",
        "    reshaped[key] = val.reshape(-1, dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVkGiVc-ZFf_"
      },
      "outputs": [],
      "source": [
        "def process_maze2d_episode(episode):\n",
        "    '''\n",
        "        adds in `next_observations` field to episode\n",
        "    '''\n",
        "    #assert 'next_observations' not in episode\n",
        "    ep = {}\n",
        "    length = len(episode.observations)\n",
        "    next_observations = episode.observations[\"observation\"][1:].copy()\n",
        "    for key, val in episode.observations.items():\n",
        "        ep[key] = val[:-1]\n",
        "    ep['next_observations'] = next_observations\n",
        "    for attr, value in vars(episode).items():\n",
        "      if attr == \"observations\":\n",
        "        continue\n",
        "      elif attr == \"terminations\":\n",
        "        ep[\"terminals\"] = value\n",
        "      elif attr == \"truncations\":\n",
        "        ep[\"timeouts\"] = value\n",
        "      elif attr == \"id\" or attr == \"seed\" or attr == \"total_timesteps\" or \"infos\"\n",
        "        continue\n",
        "      else:\n",
        "        ep[attr] = value\n",
        "\n",
        "    return ep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkYksqT8aY8d"
      },
      "outputs": [],
      "source": [
        "a = process_maze2d_episode(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcVb08Q4PTPG",
        "outputId": "c936ba38-1dc3-46b8-ebff-71d2ba710099"
      },
      "outputs": [],
      "source": [
        "print(a.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nxO9NIoTfrH",
        "outputId": "4b5b3977-db46-4e29-b86a-38cf6a6531b9"
      },
      "outputs": [],
      "source": [
        "a[\"terminals\"].any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvKzMJmf5nSP",
        "outputId": "a8fb30b5-c704-465d-e83a-2c02f22db903"
      },
      "outputs": [],
      "source": [
        "dataset[0].infos[\"goal\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8udmHX4-QPDR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JUQtkJu97Np",
        "outputId": "1cc825f3-90ab-4968-8ec4-dc08c2e94674"
      },
      "outputs": [],
      "source": [
        "for attr, value in vars(dataset[0]).items():\n",
        "    if attr == \"observations\":\n",
        "        continue\n",
        "    print(f\"{attr}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vatRKfTeUzKc",
        "outputId": "94502865-a78e-4180-dd1d-b2dd1d254fa7"
      },
      "outputs": [],
      "source": [
        "# dataset = get_dataset()\n",
        "# dataset = preprocess_fn(dataset)\n",
        "\n",
        "# N = dataset['rewards'].shape[0]\n",
        "N = dataset[0].rewards.shape[0]\n",
        "# N = dataset._data.total_episodes\n",
        "data_ = collections.defaultdict(list)\n",
        "\n",
        "# The newer version of the dataset adds an explicit\n",
        "# timeouts field. Keep old method for backwards compatability.\n",
        "use_timeouts = False\n",
        "print(N)\n",
        "episode_step = 0\n",
        "for i in range(N):\n",
        "    # print(dataset[i])\n",
        "    # dataset[i].observations\n",
        "    # done_bool = bool(dataset['terminals'][i])\n",
        "    done_bool = bool(dataset[episode_step].terminations[i])\n",
        "\n",
        "    final_timestep = episode_step == env._max_episode_steps - 1\n",
        "\n",
        "    # for k in dataset:\n",
        "    for attr, value in vars(dataset[episode_step]).items():\n",
        "        # if 'metadata' in k: continue\n",
        "        # data_[k].append(dataset[k][i])\n",
        "        data_[attr].append(value)\n",
        "\n",
        "    if done_bool or final_timestep:\n",
        "        episode_step = 0\n",
        "        episode_data = {}\n",
        "        for k in data_:\n",
        "            episode_data[k] = np.array(data_[k])\n",
        "        episode_data = process_maze2d_episode(dataset[i])\n",
        "        print(episode_data)\n",
        "        data_ = collections.defaultdict(list)\n",
        "\n",
        "        episode_step += 1\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yP4EZWUtjLEW",
        "Xh7nFzc5jxhB"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
