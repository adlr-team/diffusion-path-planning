{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRAev-KUifbW",
        "outputId": "f70d8a10-4ddb-4bd6-8f38-cbc841993bb5"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "if root_dir not in sys.path:\n",
        "    sys.path.insert(0, root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "APRB2VcQU5C2"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from diffuser.utils.config import Config, get_params, get_device_settings\n",
        "from diffuser.utils.training import Trainer\n",
        "from diffuser.utils.arrays import report_parameters, batchify\n",
        "\n",
        "import numpy as np\n",
        "import pdb\n",
        "from minari import DataCollector, StepDataCallback\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Fd7E-bLXNI"
      },
      "source": [
        "## Parse Arguments and Paramters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get settings from the config file\n",
        "\n",
        "parser = get_params()\n",
        "\n",
        "args = parser.parse_known_args(sys.argv[1:])[0]\n",
        "\n",
        "# Set Seeds\n",
        "seed = args.seed\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Get device settings\n",
        "device = get_device_settings(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzUNVoCyS54w",
        "outputId": "8fd0ca8e-cce7-456b-9438-15ca2be74525"
      },
      "outputs": [],
      "source": [
        "dataset_config = Config(\n",
        "    args.loader,\n",
        "    savepath=(args.savepath, \"dataset_config.pkl\"),\n",
        "    env=args.env_name,\n",
        "    horizon=args.horizon,\n",
        "    normalizer=args.normalizer,\n",
        "    preprocess_fns=args.preprocess_fns,\n",
        "    use_padding=args.use_padding,\n",
        "    max_path_length=args.max_path_length,\n",
        ")\n",
        "\n",
        "render_config = Config(\n",
        "    args.renderer,\n",
        "    savepath=(args.savepath, \"render_config.pkl\"),\n",
        "    env=args.env_name,\n",
        ")\n",
        "\n",
        "model_config = Config(\n",
        "    args.model,\n",
        "    savepath=(args.savepath, \"model_config.pkl\"),\n",
        "    horizon=args.horizon,\n",
        "    transition_dim=args.observation_dim + args.action_dim,\n",
        "    cond_dim=args.observation_dim,\n",
        "    dim_mults=args.dim_mults,\n",
        "    device=device,\n",
        ")\n",
        "diffusion_config = Config(\n",
        "    _class=\"models.diffuser.GaussianDiffusion\",\n",
        "    savepath=(args.savepath, \"diffusion_config.pkl\"),\n",
        "    horizon=args.horizon,\n",
        "    observation_dim=args.observation_dim,\n",
        "    action_dim=args.action_dim,\n",
        "    n_timesteps=args.n_timesteps,\n",
        "    loss_type=args.loss_type,\n",
        "    clip_denoised=args.clip_denoised,\n",
        "    predict_epsilon=args.predict_epsilon,\n",
        "    # loss weighting\n",
        "    action_weight=args.action_weight,\n",
        "    loss_weights=args.loss_weights,\n",
        "    loss_discount=args.loss_discount,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "trainer_config = Config(\n",
        "    Trainer,\n",
        "    savepath=(args.savepath, \"trainer_config.pkl\"),\n",
        "    train_batch_size=args.train_batch_size,\n",
        "    name=args.env_name,\n",
        "    train_lr=args.train_lr,\n",
        "    gradient_accumulate_every=args.gradient_accumulate_every,\n",
        "    ema_decay=args.ema_decay,\n",
        "    sample_freq=args.sample_freq,\n",
        "    save_freq=args.save_freq,\n",
        "    label_freq=args.label_freq,\n",
        "    save_parallel=args.save_parallel,\n",
        "    results_folder=args.savepath,\n",
        "    bucket=args.bucket,\n",
        "    n_reference=args.n_reference,\n",
        "    n_samples=args.n_samples,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN1wOeVGTaft",
        "outputId": "1d0e9bfe-1bca-4718-a6e9-03954dd5dbc9"
      },
      "outputs": [],
      "source": [
        "# Load objects\n",
        "dataset = dataset_config()\n",
        "renderer = render_config()\n",
        "model = model_config()\n",
        "diffuser = diffusion_config(model)\n",
        "trainer = trainer_config(diffuser, dataset, renderer, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = \"saved/10_ep/state_900000.pt\"\n",
        "trainer.load(directory=model_path, epoch=500000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make(args.env_name)\n",
        "env.reset()\n",
        "for i in range(10):\n",
        "    trainer.render_samples(env, get_cond_from_env=True, batch_size=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcJZFQl9jXtn"
      },
      "source": [
        "## Forward pass is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SnQpWsjKlRQ",
        "outputId": "6c4ce3f1-c507-42e2-e51b-485e83ed51ac"
      },
      "outputs": [],
      "source": [
        "report_parameters(model)\n",
        "\n",
        "print(\"Testing forward...\", end=\" \", flush=True)\n",
        "batch = batchify(dataset[0])\n",
        "loss, _ = diffuser.loss(*batch)\n",
        "loss.backward()\n",
        "print(\"âœ“\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2zObsfx8uFq"
      },
      "source": [
        "## Using the trainer requires taking care of the 'device' in the folders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRJlcy_WKXdq"
      },
      "source": [
        "# Training process inlcluding rendering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_time = datetime.now().strftime(\"%d_%m_%Y-%H-%M\")\n",
        "\n",
        "if args.use_wandb:\n",
        "    run = wandb.init(\n",
        "        config=args,\n",
        "        project=args.wandb_project,\n",
        "        entity=args.wandb_entity,\n",
        "        name=f\"Run_{current_time}\",\n",
        "        group=\"Group-Name\",\n",
        "        job_type=\"training\",\n",
        "        reinit=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "IaDt0qR3kczo",
        "outputId": "1ac1ee61-695b-4017-cd62-41bf7449b7b9"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# n_epochs = int(args.n_train_steps // args.n_steps_per_epoch)\n",
        "n_epochs = 5\n",
        "diffuser.to(device)\n",
        "for i in tqdm(range(n_epochs)):\n",
        "    print(f\"Epoch {i} / {n_epochs} | {args.savepath}\")\n",
        "    trainer.train(n_train_steps=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_datasets(file_path):\n",
        "    with h5py.File(file_path, \"r\") as f:\n",
        "        # Extract observations dataset\n",
        "        observations = np.array(f[\"observations\"])\n",
        "\n",
        "        # Extract infos/qpos dataset\n",
        "        qpos = np.array(f[\"infos/qpos\"])\n",
        "\n",
        "    return observations, qpos\n",
        "\n",
        "\n",
        "# Replace 'your_file_path_here' with the actual path to the HDF5 file\n",
        "file_path = \"/Users/magic-rabbit/Downloads/maze2d-large-dense-v1.hdf5\"\n",
        "observations, qpos = extract_datasets(file_path)\n",
        "\n",
        "# Printing shapes of the arrays to confirm extraction\n",
        "print(\"Observations shape:\", observations.shape)\n",
        "print(\"Qpos shape:\", qpos.shape)\n",
        "\n",
        "LARGE_MAZE = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "background_array = np.array(LARGE_MAZE)\n",
        "\n",
        "# Define the extent to center the plot at (0, 0)\n",
        "\n",
        "plt.clf()\n",
        "fig = plt.gcf()\n",
        "\n",
        "plt.imshow(\n",
        "    background_array,\n",
        "    cmap=plt.cm.binary,\n",
        "    # vmin=0,\n",
        "    # vmax=1,\n",
        ")\n",
        "\n",
        "path_length = len(observations)\n",
        "# observations = observations.reshape(len(observations), -1)\n",
        "colors = plt.cm.jet(np.linspace(0, 1, 100000))\n",
        "plt.plot(observations[:100000, 1], observations[:100000, 0], c=\"black\", zorder=10)\n",
        "plt.scatter(observations[:100000, 1], observations[:100000, 0], c=colors, zorder=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Medium\n",
        "\n",
        "# Replace 'your_file_path_here' with the actual path to the HDF5 file\n",
        "file_path = \"/Users/magic-rabbit/Downloads/maze2d-medium-dense-v1.hdf5\"\n",
        "observations, qpos = extract_datasets(file_path)\n",
        "\n",
        "# Printing shapes of the arrays to confirm extraction\n",
        "print(\"Observations shape:\", observations.shape)\n",
        "print(\"Qpos shape:\", qpos.shape)\n",
        "\n",
        "MEDIUM_MAZE = [\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 1, 0, 0, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 1, 0, 0, 0, 1, 1, 1],\n",
        "    [1, 0, 0, 1, 0, 0, 0, 1],\n",
        "    [1, 0, 1, 0, 0, 1, 0, 1],\n",
        "    [1, 0, 0, 0, 1, 0, 0, 1],\n",
        "    [1, 1, 1, 1, 1, 1, 1, 1],\n",
        "]\n",
        "background_array = np.array(MEDIUM_MAZE)\n",
        "\n",
        "\n",
        "plt.clf()\n",
        "fig = plt.gcf()\n",
        "\n",
        "plt.imshow(\n",
        "    background_array,\n",
        "    cmap=plt.cm.binary,\n",
        "    # vmin=0,\n",
        "    # vmax=1,\n",
        ")\n",
        "\n",
        "path_length = len(observations)\n",
        "# observations = observations.reshape(len(observations), -1)\n",
        "colors = plt.cm.jet(np.linspace(0, 1, 100000))\n",
        "plt.plot(observations[:100000, 1], observations[:100000, 0], c=\"black\", zorder=10)\n",
        "plt.scatter(observations[:100000, 1], observations[:100000, 0], c=colors, zorder=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualize diversity in the dataset from certain regions: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(dataset.fields)\n",
        "print(dataset.fields.observations.shape)\n",
        "\n",
        "\n",
        "start_coords = [\n",
        "    (observation[0][0], observation[0][1])\n",
        "    for observation in dataset.fields.observations\n",
        "]\n",
        "end_coords = [\n",
        "    (observation[255][0], observation[-1][1])\n",
        "    for observation in dataset.fields.observations\n",
        "]\n",
        "\n",
        "# Print min max of start and end coords\n",
        "print(\"Start coords min:\", np.min(start_coords, axis=0))\n",
        "print(\"Start coords max:\", np.max(start_coords, axis=0))\n",
        "print(\"End coords min:\", np.min(end_coords, axis=0))\n",
        "print(\"End coords max:\", np.max(end_coords, axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Initialize the trajectories list\n",
        "trajectories = []\n",
        "\n",
        "# # Create a sample start_coords and end_coords list as a tuple (x,y) betwen [-4,4]\n",
        "# start_coords = [\n",
        "#     (np.random.uniform(-4, 4), np.random.uniform(-4, 4)) for _ in range(10000)\n",
        "# ]\n",
        "# end_coords = [\n",
        "#     (np.random.uniform(-4, 4), np.random.uniform(-4, 4)) for _ in range(10000)\n",
        "# ]\n",
        "\n",
        "# print(start_coords[:5])\n",
        "# Transform the lists into the desired structure\n",
        "for start, end in zip(start_coords, end_coords):\n",
        "    trajectories.append({\"start\": start, \"end\": end})\n",
        "\n",
        "print(len(trajectories))\n",
        "# Define the boundaries for 3D\n",
        "# Creae a list with step 1 from [-4,4]\n",
        "x_boundaries = np.arange(-4, 4, 1)\n",
        "x_boundaries = [-4.0, -2.0, 0.0, 2.0, 4.0]\n",
        "y_boundaries = [-4.0, -2.0, 0.0, 2.0, 4.0]\n",
        "# Define regions\n",
        "regions = {}\n",
        "index = 1\n",
        "for i in range(4):\n",
        "    for j in range(4):\n",
        "        region_name = f\"R_{i+1}{j+1}\"\n",
        "        regions[region_name] = {\n",
        "            \"x\": (x_boundaries[i], x_boundaries[i + 1]),\n",
        "            \"y\": (y_boundaries[j], y_boundaries[j + 1]),\n",
        "        }\n",
        "        index += 1\n",
        "\n",
        "\n",
        "# Function to determine the region of a point\n",
        "def find_region(point):\n",
        "    for region, bounds in regions.items():\n",
        "        # print(f\"Bounds: {bounds}\")\n",
        "        # print(f\"Point:{point}\")\n",
        "        if (\n",
        "            bounds[\"x\"][0] <= point[0] < bounds[\"x\"][1]\n",
        "            and bounds[\"y\"][0] <= point[1] < bounds[\"y\"][1]\n",
        "        ):\n",
        "            return region\n",
        "\n",
        "    print(f\"No region found for point: {point}\")\n",
        "    print(f\"Bound: {bounds}\")\n",
        "    return None\n",
        "\n",
        "\n",
        "# Cluster trajectories\n",
        "clusters = {\n",
        "    region: {other_region: {\"count\": 0, \"indices\": []} for other_region in regions}\n",
        "    for region in regions\n",
        "}\n",
        "print(clusters)\n",
        "for idx, trajectory in enumerate(trajectories):\n",
        "    start_region = find_region(trajectory[\"start\"])\n",
        "    end_region = find_region(trajectory[\"end\"])\n",
        "    if start_region and end_region:\n",
        "        clusters[start_region][end_region][\"count\"] += 1\n",
        "        clusters[start_region][end_region][\"indices\"].append(idx)\n",
        "\n",
        "    else:\n",
        "        print(\"No matching region found\")\n",
        "        # print(trajectory[\"start\"])\n",
        "        # print(trajectory[\"end\"])\n",
        "\n",
        "\n",
        "cluster_counts = {\n",
        "    region: {\n",
        "        other_region: clusters[region][other_region][\"count\"]\n",
        "        for other_region in regions\n",
        "    }\n",
        "    for region in regions\n",
        "}\n",
        "clusters_df = pd.DataFrame(cluster_counts).T\n",
        "print(clusters_df)\n",
        "print(clusters_df.sum(axis=1).sum())\n",
        "# Get the max entry from the dataframe\n",
        "max_entry = clusters_df.max().max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_trajectories = dataset.fields.observations[clusters[\"R_33\"][\"R_13\"][\"indices\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(cluster_trajectories.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yP4EZWUtjLEW",
        "Xh7nFzc5jxhB"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
