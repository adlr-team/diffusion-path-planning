{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRAev-KUifbW",
        "outputId": "f70d8a10-4ddb-4bd6-8f38-cbc841993bb5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "if root_dir not in sys.path:\n",
        "    sys.path.insert(0, root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "APRB2VcQU5C2"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from diffuser.utils.config import Config, get_params, get_device_settings\n",
        "from justin_arm.training_justin import Justin_Trainer\n",
        "from justin_arm.helper import (\n",
        "    create_state_action_array,\n",
        "    interpolate_trajectories,\n",
        "    condition_start_end_per_trajectory,\n",
        ")\n",
        "from rokin import robots, vis\n",
        "from diffuser.utils.arrays import report_parameters, batchify\n",
        "from diffuser.datasets.sequence import TrajectoryDataset\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Render original and diffused trajectories:\n",
        "from justin_arm.visualize import (\n",
        "    plot_trajectory_per_frames,\n",
        "    plot_q_values_per_trajectory,\n",
        "    plot_multiple_trajectories,\n",
        ")\n",
        "from justin_arm.helper import robot_env_dist, analyze_distance\n",
        "from diffuser.utils.arrays import apply_dict, batch_to_device, to_device, to_np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Fd7E-bLXNI"
      },
      "source": [
        "## Parse Arguments and Paramters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The used device is gpu!\n"
          ]
        }
      ],
      "source": [
        "# Get settings from the config file\n",
        "\n",
        "parser = get_params()\n",
        "\n",
        "# overwrite params for Justin Arm\n",
        "# Define Save_path here:\n",
        "args = args = parser.parse_args(\n",
        "    [\n",
        "        \"--savepath\",\n",
        "        \"run_logs/test_123/\",\n",
        "        \"--action_dim\",\n",
        "        \"7\",\n",
        "        \"--observation_dim\",\n",
        "        \"7\",\n",
        "        \"--train_batch_size\",\n",
        "        \"32\",\n",
        "        \"--dataset\",\n",
        "        \"new_dataset\",\n",
        "        \"--horizon\",\n",
        "        \"32\",\n",
        "        \"--save_freq\",\n",
        "        \"10\",\n",
        "        \"--train_lr\",\n",
        "        \"0.0001\",\n",
        "        \"--n_timesteps\",\n",
        "        \"100\",\n",
        "        \"--scenario_name\",\n",
        "        \"justin_arm\",\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Set Seeds\n",
        "seed = args.seed\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "np.random.seed(seed)\n",
        "\n",
        "# Get device settings\n",
        "device = get_device_settings(args)\n",
        "\n",
        "# Check if saved path exists else create it :\n",
        "if not os.path.exists(args.savepath):\n",
        "    os.makedirs(args.savepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzUNVoCyS54w",
        "outputId": "8fd0ca8e-cce7-456b-9438-15ca2be74525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Interpolated_data shape:  (984, 32, 7)\n",
            "Normalized data shape: (984, 32, 7)\n",
            "Interpolated_data shape:  (942, 32, 7)\n",
            "Normalized data shape: (942, 32, 7)\n",
            "_class:models.temporal.TemporalUnet\n",
            "[ utils/config ] Imported diffuser.models.temporal:TemporalUnet\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.models.temporal.TemporalUnet'>\n",
            "    cond_dim: 7\n",
            "    dim_mults: (1, 4, 8)\n",
            "    horizon: 32\n",
            "    transition_dim: 14\n",
            "\n",
            "[ utils/config ] Saved config to: saved_full_dataset_justin_ep10_n10000/model_config.pkl\n",
            "\n",
            "_class:models.diffuser.GaussianDiffusion\n",
            "[ utils/config ] Imported diffuser.models.diffuser:GaussianDiffusion\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.models.diffuser.GaussianDiffusion'>\n",
            "    action_dim: 7\n",
            "    action_weight: 1\n",
            "    clip_denoised: True\n",
            "    horizon: 32\n",
            "    loss_discount: 1\n",
            "    loss_type: l2\n",
            "    loss_weights: None\n",
            "    n_timesteps: 100\n",
            "    observation_dim: 7\n",
            "    predict_epsilon: False\n",
            "\n",
            "[ utils/config ] Saved config to: saved_full_dataset_justin_ep10_n10000/diffusion_config.pkl\n",
            "\n",
            "\n",
            "[utils/config ] Config: <class 'justin_arm.training_justin.Justin_Trainer'>\n",
            "    bucket: None\n",
            "    ema_decay: 0.005\n",
            "    gradient_accumulate_every: 2\n",
            "    label_freq: 400\n",
            "    n_reference: 1\n",
            "    n_samples: 1\n",
            "    name: PointMaze_Medium-v3\n",
            "    results_folder: saved_full_dataset_justin_ep10_n10000/\n",
            "    sample_freq: 1000\n",
            "    save_freq: 10\n",
            "    save_parallel: False\n",
            "    train_batch_size: 32\n",
            "    train_lr: 0.0001\n",
            "\n",
            "[ utils/config ] Saved config to: saved_full_dataset_justin_ep10_n10000/trainer_config.pkl\n",
            "\n",
            "Interpolated_data shape:  (984, 32, 7)\n",
            "Normalized data shape: (984, 32, 7)\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 79\u001b[0m\n\u001b[1;32m     53\u001b[0m trainer_config \u001b[38;5;241m=\u001b[39m Config(\n\u001b[1;32m     54\u001b[0m     Justin_Trainer,\n\u001b[1;32m     55\u001b[0m     savepath\u001b[38;5;241m=\u001b[39m(args\u001b[38;5;241m.\u001b[39msavepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer_config.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     70\u001b[0m )\n\u001b[1;32m     73\u001b[0m trajectory_dataset \u001b[38;5;241m=\u001b[39m TrajectoryDataset(\n\u001b[1;32m     74\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m     75\u001b[0m     horizon\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mhorizon,\n\u001b[1;32m     76\u001b[0m     image\u001b[38;5;241m=\u001b[39mdataset_image,\n\u001b[1;32m     77\u001b[0m )\n\u001b[0;32m---> 79\u001b[0m validation_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTrajectoryDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhorizon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhorizon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_dataset_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m robot \u001b[38;5;241m=\u001b[39m robots\u001b[38;5;241m.\u001b[39mJustinArm07()\n\u001b[1;32m     87\u001b[0m model_config \u001b[38;5;241m=\u001b[39m Config(\n\u001b[1;32m     88\u001b[0m     args\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m     89\u001b[0m     savepath\u001b[38;5;241m=\u001b[39m(args\u001b[38;5;241m.\u001b[39msavepath, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_config.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     95\u001b[0m )\n",
            "File \u001b[0;32m~/Documents/ADLR/tum-adlr-ss24-18/diffuser/datasets/sequence.py:213\u001b[0m, in \u001b[0;36mTrajectoryDataset.__init__\u001b[0;34m(self, dataset, horizon, image, num_workers, batch_size)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Process dataset in batches\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m7\u001b[39m,)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalizer \u001b[38;5;241m=\u001b[39m LimitsNormalizer(\n\u001b[1;32m    216\u001b[0m     interpolate_trajectories(dataset, horizon)\n\u001b[1;32m    217\u001b[0m )\n",
            "File \u001b[0;32m~/Documents/ADLR/tum-adlr-ss24-18/diffuser/datasets/sequence.py:221\u001b[0m, in \u001b[0;36mTrajectoryDataset._batch_process\u001b[0;34m(self, dataset, num_workers)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_batch_process\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, num_workers):\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# Split dataset into batches\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m     batches \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    222\u001b[0m         dataset[i : i \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size]\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    224\u001b[0m     ]\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# Process batches in parallel\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(num_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n",
            "File \u001b[0;32m~/Documents/ADLR/tum-adlr-ss24-18/diffuser/datasets/sequence.py:222\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_batch_process\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, num_workers):\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# Split dataset into batches\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     batches \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 222\u001b[0m         \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(dataset), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m    224\u001b[0m     ]\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# Process batches in parallel\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Pool(num_workers) \u001b[38;5;28;01mas\u001b[39;00m pool:\n",
            "File \u001b[0;32m~/Documents/ADLR/tum-adlr-ss24-18/diffuser/datasets/sequence.py:240\u001b[0m, in \u001b[0;36mTrajectoryDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m    239\u001b[0m     trajectory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx]\n\u001b[0;32m--> 240\u001b[0m     conditions \u001b[38;5;241m=\u001b[39m \u001b[43mcondition_start_end_per_trajectory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m     stacked_array, actions \u001b[38;5;241m=\u001b[39m create_state_action_array(trajectory)\n\u001b[1;32m    242\u001b[0m     batch \u001b[38;5;241m=\u001b[39m Batch(stacked_array, conditions)\n",
            "File \u001b[0;32m~/Documents/ADLR/tum-adlr-ss24-18/justin_arm/helper.py:77\u001b[0m, in \u001b[0;36mcondition_start_end_per_trajectory\u001b[0;34m(q_path)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03mCalculates the start and end conditions for each trajectory in q_path.\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m      representing the start and end conditions.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# Store the dimensions of q_path in here\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m n_waypoints, n_joints \u001b[38;5;241m=\u001b[39m q_path\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Start condition is the 7th joint of the first waypoint\u001b[39;00m\n\u001b[1;32m     79\u001b[0m start_condition \u001b[38;5;241m=\u001b[39m q_path[\u001b[38;5;241m0\u001b[39m][:]\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "dataset_path = os.path.join(root_dir, \"justin_arm/data/q_paths_4123.npy\")\n",
        "dataset_image_path = os.path.join(root_dir, \"justin_arm/data/image_4123.npy\")\n",
        "\n",
        "validation_dataset_path = os.path.join(root_dir, \"justin_arm/data/q_paths_6547.npy\")\n",
        "validation_dataset_image_path = os.path.join(root_dir, \"justin_arm/data/image_6547.npy\")\n",
        "\n",
        "dataset = np.load(dataset_path)\n",
        "dataset_image = np.load(dataset_image_path)\n",
        "\n",
        "validation_dataset = np.load(validation_dataset_path)\n",
        "validation_dataset_image = np.load(validation_dataset_image_path)\n",
        "\n",
        "trajectory_dataset = TrajectoryDataset(\n",
        "    dataset=dataset,\n",
        "    horizon=args.horizon,\n",
        "    image=dataset_image,\n",
        ")\n",
        "\n",
        "validation_dataset = TrajectoryDataset(\n",
        "    dataset=validation_dataset,\n",
        "    horizon=args.horizon,\n",
        "    image=validation_dataset_image,\n",
        ")\n",
        "robot = robots.JustinArm07()\n",
        "\n",
        "\n",
        "model_config = Config(\n",
        "    args.model,\n",
        "    savepath=(args.savepath, \"model_config.pkl\"),\n",
        "    horizon=args.horizon,\n",
        "    transition_dim=args.observation_dim + args.action_dim,\n",
        "    cond_dim=args.observation_dim,\n",
        "    dim_mults=args.dim_mults,\n",
        "    device=device,\n",
        ")\n",
        "diffusion_config = Config(\n",
        "    _class=\"models.diffuser.GaussianDiffusion\",\n",
        "    savepath=(args.savepath, \"diffusion_config.pkl\"),\n",
        "    horizon=args.horizon,\n",
        "    observation_dim=args.observation_dim,\n",
        "    action_dim=args.action_dim,\n",
        "    n_timesteps=args.n_timesteps,\n",
        "    loss_type=args.loss_type,\n",
        "    clip_denoised=args.clip_denoised,\n",
        "    predict_epsilon=args.predict_epsilon,\n",
        "    # loss weighting\n",
        "    action_weight=args.action_weight,\n",
        "    loss_weights=args.loss_weights,\n",
        "    loss_discount=args.loss_discount,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "trainer_config = Config(\n",
        "    Justin_Trainer,\n",
        "    savepath=(args.savepath, \"trainer_config.pkl\"),\n",
        "    train_batch_size=args.train_batch_size,\n",
        "    train_lr=args.train_lr,\n",
        "    name=args.env_name,\n",
        "    gradient_accumulate_every=args.gradient_accumulate_every,\n",
        "    ema_decay=args.ema_decay,\n",
        "    sample_freq=args.sample_freq,\n",
        "    save_freq=args.save_freq,\n",
        "    label_freq=args.label_freq,\n",
        "    save_parallel=args.save_parallel,\n",
        "    results_folder=args.savepath,\n",
        "    bucket=args.bucket,\n",
        "    n_reference=args.n_reference,\n",
        "    n_samples=args.n_samples,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "\n",
        "trajectory_dataset = TrajectoryDataset(\n",
        "    dataset=dataset,\n",
        "    horizon=args.horizon,\n",
        "    image=dataset_image,\n",
        ")\n",
        "\n",
        "validation_dataset = TrajectoryDataset(\n",
        "    dataset=validation_dataset,\n",
        "    horizon=args.horizon,\n",
        "    image=validation_dataset_image,\n",
        ")\n",
        "robot = robots.JustinArm07()\n",
        "\n",
        "\n",
        "model_config = Config(\n",
        "    args.model,\n",
        "    savepath=(args.savepath, \"model_config.pkl\"),\n",
        "    horizon=args.horizon,\n",
        "    transition_dim=args.observation_dim + args.action_dim,\n",
        "    cond_dim=args.observation_dim,\n",
        "    dim_mults=args.dim_mults,\n",
        "    device=device,\n",
        ")\n",
        "diffusion_config = Config(\n",
        "    _class=\"models.diffuser.GaussianDiffusion\",\n",
        "    savepath=(args.savepath, \"diffusion_config.pkl\"),\n",
        "    horizon=args.horizon,\n",
        "    observation_dim=args.observation_dim,\n",
        "    action_dim=args.action_dim,\n",
        "    n_timesteps=args.n_timesteps,\n",
        "    loss_type=args.loss_type,\n",
        "    clip_denoised=args.clip_denoised,\n",
        "    predict_epsilon=args.predict_epsilon,\n",
        "    # loss weighting\n",
        "    action_weight=args.action_weight,\n",
        "    loss_weights=args.loss_weights,\n",
        "    loss_discount=args.loss_discount,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "trainer_config = Config(\n",
        "    Justin_Trainer,\n",
        "    savepath=(args.savepath, \"trainer_config.pkl\"),\n",
        "    train_batch_size=args.train_batch_size,\n",
        "    train_lr=args.train_lr,\n",
        "    name=args.env_name,\n",
        "    gradient_accumulate_every=args.gradient_accumulate_every,\n",
        "    ema_decay=args.ema_decay,\n",
        "    sample_freq=args.sample_freq,\n",
        "    save_freq=args.save_freq,\n",
        "    label_freq=args.label_freq,\n",
        "    save_parallel=args.save_parallel,\n",
        "    results_folder=args.savepath,\n",
        "    bucket=args.bucket,\n",
        "    n_reference=args.n_reference,\n",
        "    n_samples=args.n_samples,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print min and max:\n",
        "\n",
        "print(trajectory_dataset.normalizer.maxs)\n",
        "\n",
        "print(\"Min: \", np.min(trajectory_dataset.dataset))\n",
        "print(\"Max: \", np.max(trajectory_dataset.dataset))\n",
        "# Print mean and std:\n",
        "print(\"Mean: \", np.mean(trajectory_dataset.dataset))\n",
        "print(\"Std: \", np.std(trajectory_dataset.dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN1wOeVGTaft",
        "outputId": "1d0e9bfe-1bca-4718-a6e9-03954dd5dbc9"
      },
      "outputs": [],
      "source": [
        "# Load objects\n",
        "\n",
        "model = model_config()\n",
        "diffuser = diffusion_config(model)\n",
        "trainer = trainer_config(\n",
        "    diffuser,\n",
        "    trajectory_dataset,\n",
        "    validation_dataset,\n",
        "    device,\n",
        "    robot,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcJZFQl9jXtn"
      },
      "source": [
        "## Forward pass is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SnQpWsjKlRQ",
        "outputId": "6c4ce3f1-c507-42e2-e51b-485e83ed51ac"
      },
      "outputs": [],
      "source": [
        "report_parameters(model)\n",
        "\n",
        "print(\"Testing forward...\", end=\" \", flush=True)\n",
        "batch = batchify(trajectory_dataset[0])\n",
        "loss, _ = diffuser.loss(*batch)\n",
        "loss.backward()\n",
        "print(\"✓\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2zObsfx8uFq"
      },
      "source": [
        "## Using the trainer requires taking care of the 'device' in the folders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRJlcy_WKXdq"
      },
      "source": [
        "# Training process inlcluding rendering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_time = datetime.now().strftime(\"%d_%m_%Y-%H-%M\")\n",
        "\n",
        "if args.use_wandb:\n",
        "    run = wandb.init(\n",
        "        config=args,\n",
        "        project=args.wandb_project,\n",
        "        entity=args.wandb_entity,\n",
        "        name=f\"{args.savepath}_{current_time}\",\n",
        "        group=\"Group-Name\",\n",
        "        job_type=\"training\",\n",
        "        reinit=True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# n_epochs = int(args.n_train_steps // args.n_steps_per_epoch)\n",
        "n_epochs = 5\n",
        "diffuser.to(device)\n",
        "for i in tqdm(range(n_epochs)):\n",
        "    print(f\"Epoch {i} / {n_epochs} | {args.savepath}\")\n",
        "    trainer.train(n_train_steps=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training for a single datapoint : 1. Experiment!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Overfit to a single datapoint\n",
        "\n",
        "\n",
        "# Choose a single trajectory through the dataloader given a batch size of 1, then we do not know exactly what idx that is\n",
        "# single_input = next(iter(trainer.dataloader))\n",
        "# single_input = batch_to_device(single_input, device)\n",
        "\n",
        "# Choose a single trajectory arbitrarily\n",
        "single_input = batchify(validation_dataset[30])\n",
        "single_input = batch_to_device(single_input, device)\n",
        "\n",
        "# Just sample the trajectory directly from the dataset:\n",
        "# single_input_unnormalized = interpolate_trajectories(dataset[10], 32)\n",
        "\n",
        "# # Start training\n",
        "# diffuser.to(device)\n",
        "# n_epochs = 500  # Overfitting typically requires fewer epochs\n",
        "# for i in tqdm(range(n_epochs)):\n",
        "#     print(f\"Epoch {i} / {n_epochs} | {args.savepath}\")\n",
        "#     trainer.train_single_datapoint(n_train_steps=20, single_input=single_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading existing model and visualize performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and test the model on the single datapoint:\n",
        "model_path = \"saved_full_dataset_justin_ep10_n10000//state_250000.pt\"\n",
        "trainer.load(directory=model_path, epoch=25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot the trajectory taken directly from the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Plor the orginal trajectory\n",
        "# %matplotlib inline\n",
        "\n",
        "# # Plot the original and diffused trajectories:\n",
        "# # Original:\n",
        "\n",
        "# # Get collision_metric:\n",
        "# distance = robot_env_dist(\n",
        "#     q=single_input_unnormalized[0], robot=trainer.robot, img=trainer.dataset.image[0]\n",
        "# )\n",
        "\n",
        "# score = analyze_distance(distance)\n",
        "\n",
        "# print(f\"Collision score: {score}\")\n",
        "\n",
        "\n",
        "# print(single_input_unnormalized[0].shape)\n",
        "\n",
        "# plot_trajectory_per_frames(single_input_unnormalized[0])\n",
        "# plot_q_values_per_trajectory(single_input_unnormalized[0])\n",
        "\n",
        "\n",
        "# limits = np.array([[-1.25, +1.25], [-1.25, +1.25], [-1.25, +1.25]])\n",
        "# vis.three_pv.animate_path(\n",
        "#     robot=trainer.robot,\n",
        "#     q=single_input_unnormalized[0],\n",
        "#     kwargs_robot=dict(color=\"red\"),\n",
        "#     kwargs_world=dict(img=trainer.dataset.image[0], limits=limits, color=\"yellow\"),\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting the reference trajectory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "trainer.plot_reference_data(single_input)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plotting the diffused reconstruction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now plotting for the diffused trajectory:\n",
        "%matplotlib inline\n",
        "collision_score = trainer.render_given_sample(single_input, render_3d=False)\n",
        "print(f\"Collision score: {collision_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Out of wqorld generalization:\n",
        "dataset = np.load(\"justin_arm/data/q_paths_6547.npy\")\n",
        "dataset_image = np.load(\"justin_arm/data/image_6547.npy\")\n",
        "trajectory_dataset = TrajectoryDataset(\n",
        "    dataset=dataset, horizon=args.horizon, image=dataset_image\n",
        ")\n",
        "\n",
        "robot = robots.JustinArm07()\n",
        "trainer = trainer_config(diffuser, trajectory_dataset, device, robot)\n",
        "\n",
        "\n",
        "# Load model:\n",
        "# Load and test the model on the single datapoint:\n",
        "model_path = \"saved_justin_ep100_n100//state_10000.pt\"\n",
        "trainer.load(directory=model_path, epoch=100)\n",
        "\n",
        "\n",
        "# Load random datapoints:\n",
        "single_input = batchify(trajectory_dataset[10])\n",
        "single_input = batch_to_device(single_input, device)\n",
        "\n",
        "\n",
        "# Compare reference and diffusion:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "collision_score = trainer.plot_reference_data(single_input, render_3d=False)\n",
        "print(f\"Collision score: {collision_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now plotting for the diffused trajectory:\n",
        "%matplotlib inline\n",
        "# empty ndarray of shape (0,args.horizon,7)\n",
        "q_paths = np.zeros((0, args.horizon, 7))\n",
        "collision_scores= []\n",
        "for i in range(20):\n",
        "    q_path, collision_score = trainer.render_given_sample(single_input, render_3d=False)\n",
        "    collision_scores.append(collision_score)\n",
        "    q_path = np.expand_dims(q_path, axis=0)\n",
        "    q_paths = np.append(q_paths, q_path, axis=0)\n",
        "\n",
        "print(f\"Mean collision score: {np.mean(collision_scores)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = interpolate_trajectories(dataset, 32)\n",
        "print(dataset.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plot_multiple_trajectories(q_paths[:20], q_paths.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load 4123\n",
        "\n",
        "\n",
        "def plot_q_values_per_trajectory(q_paths, savepath=os.getcwd(), name=\"default\"):\n",
        "    \"\"\"\n",
        "    Plot the Q-values over the waypoints for each joint in the robot.\n",
        "\n",
        "    Args:\n",
        "        q_paths (ndarray): Array of Q-values for each joint over different trajectories.\n",
        "            Shape of the array should be (num_paths, waypoints, joints).\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    # Third plot: Q-value plots for each joint\n",
        "    fig3, axs = plt.subplots(4, 2, figsize=(12, 12))  # 4 rows, 2 columns (8 subplots)\n",
        "\n",
        "    # Flatten the axs array for easy iteration, ignoring the last subplot\n",
        "    axs = axs.flatten()\n",
        "    if q_paths.ndim == 2:\n",
        "        q_paths = np.expand_dims(q_paths, axis=0)\n",
        "\n",
        "    num_paths, waypoints, joints = q_paths.shape\n",
        "\n",
        "    # Create subplots for each joint\n",
        "    for j in range(joints):\n",
        "        ax = axs[j]\n",
        "        ax.set_xlabel(\"Waypoints\")\n",
        "        ax.set_ylabel(f\"Q value of Joint {j + 1}\")\n",
        "        for i in range(num_paths):\n",
        "            ax.plot(q_paths[i, :, j], color=\"black\", zorder=10)\n",
        "            ax.scatter(\n",
        "                range(q_paths.shape[1]),\n",
        "                q_paths[i, :, j],\n",
        "                c=plt.cm.jet(np.linspace(0, 1, waypoints)),\n",
        "                zorder=10,\n",
        "            )\n",
        "\n",
        "    # Remove the 8th (extra) subplot\n",
        "    fig3.delaxes(axs[-1])\n",
        "\n",
        "    # Adjust layout to prevent overlap\n",
        "    plt.tight_layout()\n",
        "    # Show the third plot\n",
        "    plt.savefig(f\"{savepath}/q_values_{name}.png\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_q_values_per_trajectory(q_paths, savepath=\".\", name=\"diffused\")\n",
        "plot_multiple_trajectories(q_paths)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yP4EZWUtjLEW",
        "Xh7nFzc5jxhB"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
