{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRAev-KUifbW",
        "outputId": "f70d8a10-4ddb-4bd6-8f38-cbc841993bb5"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
        "if root_dir not in sys.path:\n",
        "    sys.path.insert(0, root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "APRB2VcQU5C2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/magic-rabbit/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from diffuser.utils.config import Config\n",
        "import collections\n",
        "import numpy as np\n",
        "import pdb\n",
        "from minari import DataCollector, StepDataCallback\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Fd7E-bLXNI"
      },
      "source": [
        "## Diffuser Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rg9GmmXWStiK"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(\n",
        "        self,\n",
        "        loader,\n",
        "        savepath,\n",
        "        dataset,\n",
        "        horizon,\n",
        "        normalizer,\n",
        "        preprocess_fns,\n",
        "        use_padding,\n",
        "        max_path_length,\n",
        "        renderer,\n",
        "        model,\n",
        "        dim_mults,\n",
        "        device,\n",
        "    ):\n",
        "        self.loader = loader\n",
        "        self.savepath = savepath\n",
        "        self.dataset = dataset\n",
        "        self.horizon = horizon\n",
        "        self.normalizer = normalizer\n",
        "        self.preprocess_fns = preprocess_fns\n",
        "        self.use_padding = use_padding\n",
        "        self.max_path_length = max_path_length\n",
        "        self.renderer = renderer\n",
        "        self.model = model\n",
        "        # self.transition_dim=transition_dim\n",
        "        # self.cond_dim=cond_dim\n",
        "        self.dim_mults = dim_mults\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "args = Args(\n",
        "    loader=\"datasets.sequence.GoalDataset\",\n",
        "    savepath=\"saved/\",\n",
        "    dataset=\"PointMaze_Large-v3\",\n",
        "    horizon=256,\n",
        "    normalizer=\"LimitsNormalizer\",\n",
        "    preprocess_fns=[\"maze2d_set_terminals\"],\n",
        "    use_padding=False,\n",
        "    max_path_length=100000,\n",
        "    renderer=\"utils.rendering.Maze2dRenderer\",\n",
        "    model=\"models.temporal.TemporalUnet\",\n",
        "    dim_mults=(1, 4, 8),\n",
        "    device=\"cuda\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzUNVoCyS54w",
        "outputId": "8fd0ca8e-cce7-456b-9438-15ca2be74525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:datasets.sequence.GoalDataset\n",
            "[ utils/config ] Imported diffuser.datasets.sequence:GoalDataset\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.datasets.sequence.GoalDataset'>\n",
            "    env: PointMaze_Large-v3\n",
            "    horizon: 256\n",
            "    max_path_length: 100000\n",
            "    normalizer: LimitsNormalizer\n",
            "    preprocess_fns: ['maze2d_set_terminals']\n",
            "    use_padding: False\n",
            "\n",
            "[ utils/config ] Saved config to: saved/dataset_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset_config = Config(\n",
        "    args.loader,\n",
        "    savepath=(args.savepath, \"dataset_config.pkl\"),\n",
        "    env=args.dataset,\n",
        "    horizon=args.horizon,\n",
        "    normalizer=args.normalizer,\n",
        "    preprocess_fns=args.preprocess_fns,\n",
        "    use_padding=args.use_padding,\n",
        "    max_path_length=args.max_path_length,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN1wOeVGTaft",
        "outputId": "1d0e9bfe-1bca-4718-a6e9-03954dd5dbc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the enviornment: PointMaze_Large-v3\n",
            "Name of the enviornment: PointMaze_Large-v3\n",
            "Dataset_name:pointmaze-umaze-v0\n",
            "dataset exists!\n",
            "100000\n",
            "[ datasets/buffer ] Finalized replay buffer | 1 episodes\n",
            "[ datasets/buffer ] Fields:\n",
            "    achieved_goal: (1, 100000, 2)\n",
            "    desired_goal: (1, 100000, 2)\n",
            "    observations: (1, 100000, 4)\n",
            "    observation: (1, 100000, 4)\n",
            "    next_observations: (1, 100000, 4)\n",
            "    actions: (1, 100000, 2)\n",
            "    terminals: (1, 100000, 1)\n",
            "    timeouts: (1, 100000, 1)\n",
            "[ datasets/buffer ] Fields:\n",
            "    achieved_goal: (1, 100000, 2)\n",
            "    desired_goal: (1, 100000, 2)\n",
            "    observations: (1, 100000, 4)\n",
            "    observation: (1, 100000, 4)\n",
            "    next_observations: (1, 100000, 4)\n",
            "    actions: (1, 100000, 2)\n",
            "    terminals: (1, 100000, 1)\n",
            "    timeouts: (1, 100000, 1)\n",
            "    normed_observations: (1, 100000, 4)\n",
            "    normed_actions: (1, 100000, 2)\n"
          ]
        }
      ],
      "source": [
        "dataset = dataset_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvk2JJzc6BO6",
        "outputId": "89b725cd-4487-4716-e55f-9b346b7e4e95"
      },
      "outputs": [],
      "source": [
        "# dataset[1]\n",
        "# dataset[1].observations[\"observation\"][:, :2]\n",
        "# dataset[1].total_steps\n",
        "# env = gym.make(\"PointMaze_Large-v3\")\n",
        "# env._max_episode_steps\n",
        "# # env.target\n",
        "# np.array(wrapped_env.observation_space[\"desired_goal\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENDornlpjRvY"
      },
      "source": [
        "## Configs for Rendering and the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bme6emjGVS6-",
        "outputId": "847b6b49-3758-4e5a-9e0c-3e3872f65259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:utils.rendering.Maze2dRenderer\n",
            "[ utils/config ] Imported diffuser.utils.rendering:Maze2dRenderer\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.utils.rendering.Maze2dRenderer'>\n",
            "    env: PointMaze_Large-v3\n",
            "\n",
            "[ utils/config ] Saved config to: saved/render_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "render_config = Config(\n",
        "    args.renderer,\n",
        "    savepath=(args.savepath, \"render_config.pkl\"),\n",
        "    env=args.dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtDYVRdctm86",
        "outputId": "3c4a10d7-ccde-41d4-f7cf-19404180f063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:models.temporal.TemporalUnet\n",
            "[ utils/config ] Imported diffuser.models.temporal:TemporalUnet\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.models.temporal.TemporalUnet'>\n",
            "    cond_dim: 4\n",
            "    dim_mults: (1, 4, 8)\n",
            "    horizon: 256\n",
            "    transition_dim: 6\n",
            "\n",
            "[ utils/config ] Saved config to: saved/model_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# observation_dim = dataset.observation_dim\n",
        "# action_dim = dataset.action_dim\n",
        "observation_dim = 4\n",
        "action_dim = 2\n",
        "# -----------------------------------------------------------------------------#\n",
        "# ------------------------------ model & trainer ------------------------------#\n",
        "# -----------------------------------------------------------------------------#\n",
        "\n",
        "model_config = Config(\n",
        "    args.model,\n",
        "    savepath=(args.savepath, \"model_config.pkl\"),\n",
        "    horizon=args.horizon,\n",
        "    transition_dim=observation_dim + action_dim,\n",
        "    cond_dim=observation_dim,\n",
        "    dim_mults=args.dim_mults,\n",
        "    device=args.device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLILqE_ZrBdy",
        "outputId": "2a032e3e-bf83-48a1-f186-e1c5a62a5e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the enviornment: PointMaze_Large-v3\n"
          ]
        }
      ],
      "source": [
        "renderer = render_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0362NXnEtqzJ",
        "outputId": "b3be0703-1e9a-4fb4-fba6-bc14a3052215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ models/temporal ] Channel dimensions: [(6, 32), (32, 128), (128, 256)]\n",
            "[(6, 32), (32, 128), (128, 256)]\n"
          ]
        }
      ],
      "source": [
        "model = model_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56UTrirwtof5",
        "outputId": "a0d92bcc-c4f6-41bd-fa4f-54d7887afa4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:models.diffuser.GaussianDiffusion\n",
            "[ utils/config ] Imported diffuser.models.diffuser:GaussianDiffusion\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.models.diffuser.GaussianDiffusion'>\n",
            "    action_dim: 2\n",
            "    action_weight: 1\n",
            "    clip_denoised: True\n",
            "    horizon: 256\n",
            "    loss_discount: 1\n",
            "    loss_type: l2\n",
            "    loss_weights: None\n",
            "    n_timesteps: 256\n",
            "    observation_dim: 4\n",
            "    predict_epsilon: False\n",
            "\n",
            "[ utils/config ] Saved config to: saved/diffusion_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "diffusion_config = Config(\n",
        "    _class=\"models.diffuser.GaussianDiffusion\",\n",
        "    savepath=(args.savepath, \"diffusion_config.pkl\"),\n",
        "    horizon=256,\n",
        "    observation_dim=observation_dim,\n",
        "    action_dim=2,\n",
        "    n_timesteps=256,\n",
        "    loss_type=\"l2\",\n",
        "    clip_denoised=True,\n",
        "    predict_epsilon=False,\n",
        "    # loss weighting\n",
        "    action_weight=1,\n",
        "    loss_weights=None,\n",
        "    loss_discount=1,\n",
        "    device=args.device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "qUBUMLX-KX-D"
      },
      "outputs": [],
      "source": [
        "diffuser = diffusion_config(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcJZFQl9jXtn"
      },
      "source": [
        "## Forward pass is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SnQpWsjKlRQ",
        "outputId": "6c4ce3f1-c507-42e2-e51b-485e83ed51ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ utils/arrays ] Total parameters: 3.68 M\n",
            "         downs.2.0.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.2.1.blocks.0.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.2.1.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         ups.0.0.blocks.0.block.0.weight: 327.68 k | Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block1.blocks.0.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block1.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block2.blocks.0.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block2.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.2.0.blocks.0.block.0.weight: 163.84 k | Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.1.0.blocks.1.block.0.weight: 81.92 k | Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         ... and 138 others accounting for 814.92 k parameters\n",
            "Testing forward... "
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting forward...\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      9\u001b[0m batch \u001b[38;5;241m=\u001b[39m batchify(dataset[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m loss, _ \u001b[38;5;241m=\u001b[39m \u001b[43mdiffuser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✓\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/diffuser/models/diffuser.py:240\u001b[0m, in \u001b[0;36mGaussianDiffusion.loss\u001b[0;34m(self, x, cond)\u001b[0m\n\u001b[1;32m    238\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[1;32m    239\u001b[0m t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_timesteps, (batch_size,), device\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdevice)\u001b[38;5;241m.\u001b[39mlong()\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp_losses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/diffuser/models/diffuser.py:225\u001b[0m, in \u001b[0;36mGaussianDiffusion.p_losses\u001b[0;34m(self, x_start, cond, t)\u001b[0m\n\u001b[1;32m    222\u001b[0m x_noisy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_sample(x_start\u001b[38;5;241m=\u001b[39mx_start, t\u001b[38;5;241m=\u001b[39mt, noise\u001b[38;5;241m=\u001b[39mnoise)\n\u001b[1;32m    223\u001b[0m x_noisy \u001b[38;5;241m=\u001b[39m apply_conditioning(x_noisy, cond, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim)\n\u001b[0;32m--> 225\u001b[0m x_recon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_noisy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m x_recon \u001b[38;5;241m=\u001b[39m apply_conditioning(x_recon, cond, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_dim)\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m noise\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m x_recon\u001b[38;5;241m.\u001b[39mshape\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/diffuser/models/temporal.py:113\u001b[0m, in \u001b[0;36mTemporalUnet.forward\u001b[0;34m(self, x, cond, time)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m    x : [ batch x horizon x transition ]\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    111\u001b[0m x \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(x, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mb h t -> b t h\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m h \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m resnet, resnet2, downsample \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdowns:\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/torch/utils/_device.py:78\u001b[0m, in \u001b[0;36mDeviceContext.__torch_function__\u001b[0;34m(self, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m _device_constructors() \u001b[38;5;129;01mand\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     77\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
          ]
        }
      ],
      "source": [
        "from diffuser.utils.arrays import report_parameters, batchify\n",
        "import torch\n",
        "\n",
        "torch.set_default_device(\"cuda\")  # current device is 0\n",
        "\n",
        "report_parameters(model)\n",
        "diffuser.to(\"cuda\")\n",
        "print(\"Testing forward...\", end=\" \", flush=True)\n",
        "batch = batchify(dataset[0])\n",
        "loss, _ = diffuser.loss(*batch)\n",
        "loss.backward()\n",
        "print(\"✓\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2zObsfx8uFq"
      },
      "source": [
        "## Using the trainer requires taking care of the 'device' in the folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Ahsw3rhEeF",
        "outputId": "72015822-2ea3-4d8d-df37-76026af74d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[utils/config ] Config: <class 'diffuser.utils.training.Trainer'>\n",
            "    bucket: None\n",
            "    ema_decay: 0.005\n",
            "    gradient_accumulate_every: 2\n",
            "    label_freq: 400\n",
            "    n_reference: 1\n",
            "    n_samples: 1\n",
            "    results_folder: saved/\n",
            "    sample_freq: 1000\n",
            "    save_freq: 1000\n",
            "    save_parallel: False\n",
            "    train_batch_size: 32\n",
            "    train_lr: 0.0002\n",
            "\n",
            "[ utils/config ] Saved config to: saved/trainer_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from diffuser.utils.training import Trainer\n",
        "\n",
        "trainer_config = Config(\n",
        "    Trainer,\n",
        "    savepath=(args.savepath, \"trainer_config.pkl\"),\n",
        "    train_batch_size=32,\n",
        "    train_lr=2e-4,\n",
        "    gradient_accumulate_every=2,\n",
        "    ema_decay=0.005,\n",
        "    sample_freq=1000,\n",
        "    save_freq=1000,\n",
        "    label_freq=int(2e4 // 50),\n",
        "    save_parallel=False,\n",
        "    results_folder=args.savepath,\n",
        "    bucket=None,\n",
        "    n_reference=1,\n",
        "    n_samples=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KcB-OnzvkFgn"
      },
      "outputs": [],
      "source": [
        "trainer = trainer_config(diffuser, dataset, renderer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRJlcy_WKXdq"
      },
      "source": [
        "# Training process inlcluding rendering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "IaDt0qR3kczo",
        "outputId": "1ac1ee61-695b-4017-cd62-41bf7449b7b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 / 2 | saved/\n"
          ]
        },
        {
          "ename": "Error",
          "evalue": "You must call wandb.init() before wandb.log()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39msavepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_train_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/diffuser/utils/training.py:133\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, n_train_steps)\u001b[0m\n\u001b[1;32m    131\u001b[0m timer \u001b[38;5;241m=\u001b[39m Timer()\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_train_steps):\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining_steps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_accumulate_every):\n\u001b[1;32m    135\u001b[0m         batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader)\n",
            "File \u001b[0;32m~/tum-adlr-ss24-18/.venv/lib/python3.10/site-packages/wandb/sdk/lib/preinit.py:36\u001b[0m, in \u001b[0;36mPreInitCallable.<locals>.preinit_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreinit_wrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must call wandb.init() before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mError\u001b[0m: You must call wandb.init() before wandb.log()"
          ]
        }
      ],
      "source": [
        "# n_epochs = int(args.n_train_steps // args.n_steps_per_epoch)\n",
        "n_epochs = 2\n",
        "for i in range(n_epochs):\n",
        "    print(f\"Epoch {i} / {n_epochs} | {args.savepath}\")\n",
        "    trainer.train(n_train_steps=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh7nFzc5jxhB"
      },
      "source": [
        "## Random Test (don't run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDUP3qKtE5Kw",
        "outputId": "518943ce-53b7-483f-c3bf-b73305daee0b"
      },
      "outputs": [],
      "source": [
        "from contextlib import (\n",
        "    contextmanager,\n",
        "    redirect_stderr,\n",
        "    redirect_stdout,\n",
        ")\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def suppress_output():\n",
        "    \"\"\"\n",
        "    A context manager that redirects stdout and stderr to devnull\n",
        "    https://stackoverflow.com/a/52442331\n",
        "    \"\"\"\n",
        "    with open(os.devnull, \"w\") as fnull:\n",
        "        with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:\n",
        "            yield (err, out)\n",
        "\n",
        "\n",
        "# with suppress_output():\n",
        "#     ## d4rl prints out a variety of warnings\n",
        "#     import d4rl\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# -------------------------------- general api --------------------------------#\n",
        "# -----------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "def load_environment(name):\n",
        "    print(name)\n",
        "    if type(name) != str:\n",
        "        # name is already an environment\n",
        "        return name\n",
        "    with suppress_output():\n",
        "        wrapped_env = gym.make(name)\n",
        "    env = wrapped_env.unwrapped\n",
        "    env.max_episode_steps = wrapped_env._max_episode_steps\n",
        "    env.name = name\n",
        "    return env\n",
        "\n",
        "\n",
        "class PointMazeStepDataCallback(StepDataCallback):\n",
        "    \"\"\"Add environment state information to 'infos'.\n",
        "\n",
        "    Also, since the environment generates a new target every time it reaches a goal, the environment is\n",
        "    never terminated or truncated. This callback overrides the truncation value to True when the step\n",
        "    returns a True 'succes' key in 'infos'. This way we can divide the Minari dataset into different trajectories.\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(\n",
        "        self, env, obs, info, action=None, rew=None, terminated=None, truncated=None\n",
        "    ):\n",
        "        qpos = obs[\"observation\"][:2]\n",
        "        qvel = obs[\"observation\"][2:]\n",
        "        goal = obs[\"desired_goal\"]\n",
        "\n",
        "        step_data = super().__call__(env, obs, info, action, rew, terminated, truncated)\n",
        "\n",
        "        if step_data[\"infos\"][\"success\"]:\n",
        "            step_data[\"truncation\"] = True\n",
        "        step_data[\"infos\"][\"qpos\"] = qpos\n",
        "        step_data[\"infos\"][\"qvel\"] = qvel\n",
        "        step_data[\"infos\"][\"goal\"] = goal\n",
        "\n",
        "        return step_data\n",
        "\n",
        "\n",
        "UP = 0\n",
        "DOWN = 1\n",
        "LEFT = 2\n",
        "RIGHT = 3\n",
        "\n",
        "EXPLORATION_ACTIONS = {UP: (0, 1), DOWN: (0, -1), LEFT: (-1, 0), RIGHT: (1, 0)}\n",
        "\n",
        "\n",
        "class QIteration:\n",
        "    \"\"\"Solves for optimal policy with Q-Value Iteration.\n",
        "\n",
        "    Inspired by https://github.com/Farama-Foundation/D4RL/blob/master/d4rl/pointmaze/q_iteration.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, maze):\n",
        "        self.maze = maze\n",
        "        self.num_states = maze.map_length * maze.map_width\n",
        "        self.num_actions = len(EXPLORATION_ACTIONS.keys())\n",
        "        self.rew_matrix = np.zeros((self.num_states, self.num_actions))\n",
        "        self.compute_transition_matrix()\n",
        "\n",
        "    def generate_path(self, current_cell, goal_cell):\n",
        "        self.compute_reward_matrix(goal_cell)\n",
        "        q_values = self.get_q_values()\n",
        "        current_state = self.cell_to_state(current_cell)\n",
        "        waypoints = {}\n",
        "        while True:\n",
        "            action_id = np.argmax(q_values[current_state])\n",
        "            next_state, _ = self.get_next_state(\n",
        "                current_state, EXPLORATION_ACTIONS[action_id]\n",
        "            )\n",
        "            current_cell = self.state_to_cell(current_state)\n",
        "            waypoints[current_cell] = self.state_to_cell(next_state)\n",
        "            if waypoints[current_cell] == goal_cell:\n",
        "                break\n",
        "\n",
        "            current_state = next_state\n",
        "\n",
        "        return waypoints\n",
        "\n",
        "    def reward_function(self, desired_cell, current_cell):\n",
        "        if desired_cell == current_cell:\n",
        "            return 1.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def state_to_cell(self, state):\n",
        "        i = int(state / self.maze.map_width)\n",
        "        j = state % self.maze.map_width\n",
        "        return (i, j)\n",
        "\n",
        "    def cell_to_state(self, cell):\n",
        "        return cell[0] * self.maze.map_width + cell[1]\n",
        "\n",
        "    def get_q_values(self, num_itrs=50, discount=0.99):\n",
        "        q_fn = np.zeros((self.num_states, self.num_actions))\n",
        "        for _ in range(num_itrs):\n",
        "            v_fn = np.max(q_fn, axis=1)\n",
        "            q_fn = self.rew_matrix + discount * self.transition_matrix.dot(v_fn)\n",
        "        return q_fn\n",
        "\n",
        "    def compute_reward_matrix(self, goal_cell):\n",
        "        for state in range(self.num_states):\n",
        "            for action in range(self.num_actions):\n",
        "                next_state, _ = self.get_next_state(state, EXPLORATION_ACTIONS[action])\n",
        "                next_cell = self.state_to_cell(next_state)\n",
        "                self.rew_matrix[state, action] = self.reward_function(\n",
        "                    goal_cell, next_cell\n",
        "                )\n",
        "\n",
        "    def compute_transition_matrix(self):\n",
        "        \"\"\"Constructs this environment's transition matrix.\n",
        "        Returns:\n",
        "          A dS x dA x dS array where the entry transition_matrix[s, a, ns]\n",
        "          corresponds to the probability of transitioning into state ns after taking\n",
        "          action a from state s.\n",
        "        \"\"\"\n",
        "        self.transition_matrix = np.zeros(\n",
        "            (self.num_states, self.num_actions, self.num_states)\n",
        "        )\n",
        "        for state in range(self.num_states):\n",
        "            for action_idx, action in EXPLORATION_ACTIONS.items():\n",
        "                next_state, valid = self.get_next_state(state, action)\n",
        "                if valid:\n",
        "                    self.transition_matrix[state, action_idx, next_state] = 1\n",
        "\n",
        "    def get_next_state(self, state, action):\n",
        "        cell = self.state_to_cell(state)\n",
        "\n",
        "        next_cell = tuple(map(lambda i, j: int(i + j), cell, action))\n",
        "        next_state = self.cell_to_state(next_cell)\n",
        "\n",
        "        return next_state, self._check_valid_cell(next_cell)\n",
        "\n",
        "    def _check_valid_cell(self, cell):\n",
        "        # Out of map bounds\n",
        "        if cell[0] >= self.maze.map_length:\n",
        "            return False\n",
        "        elif cell[1] >= self.maze.map_width:\n",
        "            return False\n",
        "        # Wall collision\n",
        "        elif self.maze.maze_map[cell[0]][cell[1]] == 1:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "\n",
        "class WaypointController:\n",
        "    \"\"\"Agent controller to follow waypoints in the maze.\n",
        "\n",
        "    Inspired by https://github.com/Farama-Foundation/D4RL/blob/master/d4rl/pointmaze/waypoint_controller.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, maze, gains={\"p\": 10.0, \"d\": -1.0}, waypoint_threshold=0.1):\n",
        "        self.global_target_xy = np.empty(2)\n",
        "        self.maze = maze\n",
        "\n",
        "        self.maze_solver = QIteration(maze=self.maze)\n",
        "\n",
        "        self.gains = gains\n",
        "        self.waypoint_threshold = waypoint_threshold\n",
        "        self.waypoint_targets = None\n",
        "\n",
        "    def compute_action(self, obs):\n",
        "        # Check if we need to generate new waypoint path due to change in global target\n",
        "        if (\n",
        "            np.linalg.norm(self.global_target_xy - obs[\"desired_goal\"]) > 1e-3\n",
        "            or self.waypoint_targets is None\n",
        "        ):\n",
        "            # Convert xy to cell id\n",
        "            achieved_goal_cell = tuple(\n",
        "                self.maze.cell_xy_to_rowcol(obs[\"achieved_goal\"])\n",
        "            )\n",
        "            self.global_target_id = tuple(\n",
        "                self.maze.cell_xy_to_rowcol(obs[\"desired_goal\"])\n",
        "            )\n",
        "            self.global_target_xy = obs[\"desired_goal\"]\n",
        "\n",
        "            self.waypoint_targets = self.maze_solver.generate_path(\n",
        "                achieved_goal_cell, self.global_target_id\n",
        "            )\n",
        "\n",
        "            # Check if the waypoint dictionary is empty\n",
        "            # If empty then the ball is already in the target cell location\n",
        "            if self.waypoint_targets:\n",
        "                self.current_control_target_id = self.waypoint_targets[\n",
        "                    achieved_goal_cell\n",
        "                ]\n",
        "                self.current_control_target_xy = self.maze.cell_rowcol_to_xy(\n",
        "                    np.array(self.current_control_target_id)\n",
        "                )\n",
        "            else:\n",
        "                self.waypoint_targets[self.current_control_target_id] = (\n",
        "                    self.current_control_target_id\n",
        "                )\n",
        "                self.current_control_target_id = self.global_target_id\n",
        "                self.current_control_target_xy = self.global_target_xy\n",
        "\n",
        "        # Check if we need to go to the next waypoint\n",
        "        dist = np.linalg.norm(self.current_control_target_xy - obs[\"achieved_goal\"])\n",
        "        if (\n",
        "            dist <= self.waypoint_threshold\n",
        "            and self.current_control_target_id != self.global_target_id\n",
        "        ):\n",
        "            self.current_control_target_id = self.waypoint_targets[\n",
        "                self.current_control_target_id\n",
        "            ]\n",
        "            # If target is global goal go directly to goal position\n",
        "            if self.current_control_target_id == self.global_target_id:\n",
        "                self.current_control_target_xy = self.global_target_xy\n",
        "            else:\n",
        "                self.current_control_target_xy = (\n",
        "                    self.maze.cell_rowcol_to_xy(\n",
        "                        np.array(self.current_control_target_id)\n",
        "                    )\n",
        "                    - np.random.uniform(size=(2,)) * 0.2\n",
        "                )\n",
        "\n",
        "        action = (\n",
        "            self.gains[\"p\"] * (self.current_control_target_xy - obs[\"achieved_goal\"])\n",
        "            + self.gains[\"d\"] * obs[\"observation\"][2:]\n",
        "        )\n",
        "        action = np.clip(action, -1, 1)\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "def get_dataset():\n",
        "    # Code from Minari documentation\n",
        "    dataset_name = \"pointmaze-umaze-v0\"\n",
        "    total_steps = 20_000\n",
        "\n",
        "    # continuing task => the episode doesn't terminate or truncate when reaching a goal\n",
        "    # it will generate a new target. For this reason we set the maximum episode steps to\n",
        "    # the desired size of our Minari dataset (evade truncation due to time limit)\n",
        "    env = gym.make(\n",
        "        \"PointMaze_Medium-v3\", continuing_task=True, max_episode_steps=total_steps // 2\n",
        "    )\n",
        "\n",
        "    # Data collector wrapper to save temporary data while stepping. Characteristics:\n",
        "    #   * Custom StepDataCallback to add extra state information to 'infos' and divide dataset in different episodes by overridng\n",
        "    #     truncation value to True when target is reached\n",
        "    #   * Record the 'info' value of every step\n",
        "    collector_env = DataCollector(\n",
        "        env, step_data_callback=PointMazeStepDataCallback, record_infos=True\n",
        "    )\n",
        "\n",
        "    obs, _ = collector_env.reset(seed=123)\n",
        "\n",
        "    waypoint_controller = WaypointController(maze=env.maze)\n",
        "\n",
        "    for n_step in range(int(total_steps)):\n",
        "        action = waypoint_controller.compute_action(obs)\n",
        "        # Add some noise to each step action\n",
        "        action += np.random.randn(*action.shape) * 0.5\n",
        "        action = np.clip(\n",
        "            action, env.action_space.low, env.action_space.high, dtype=np.float32\n",
        "        )\n",
        "\n",
        "        obs, rew, terminated, truncated, info = collector_env.step(action)\n",
        "\n",
        "    dataset = collector_env.create_dataset(\n",
        "        dataset_id=dataset_name,\n",
        "        algorithm_name=\"QIteration\",\n",
        "        code_permalink=\"https://github.com/Farama-Foundation/Minari/blob/main/docs/tutorials/dataset_creation/point_maze_dataset.py\",\n",
        "        author=\"Rodrigo Perez-Vicente\",\n",
        "        author_email=\"rperezvicente@farama.org\",\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "\n",
        "dataset = get_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "Qb0DuGNZQMbE",
        "outputId": "2dbcd2a9-9641-4daa-92bb-956bc8a03754"
      },
      "outputs": [],
      "source": [
        "print(dataset)\n",
        "print(dataset[\"actions\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "vugWLtYdZedT",
        "outputId": "12030896-dac2-4e04-f7c9-751cf3f9d8b1"
      },
      "outputs": [],
      "source": [
        "reshaped = {}\n",
        "for key, val in dataset.items():\n",
        "    dim = val.shape[-1]\n",
        "    reshaped[key] = val.reshape(-1, dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVkGiVc-ZFf_"
      },
      "outputs": [],
      "source": [
        "def process_maze2d_episode(episode):\n",
        "    '''\n",
        "        adds in `next_observations` field to episode\n",
        "    '''\n",
        "    #assert 'next_observations' not in episode\n",
        "    ep = {}\n",
        "    length = len(episode.observations)\n",
        "    next_observations = episode.observations[\"observation\"][1:].copy()\n",
        "    for key, val in episode.observations.items():\n",
        "        ep[key] = val[:-1]\n",
        "    ep['next_observations'] = next_observations\n",
        "    for attr, value in vars(episode).items():\n",
        "      if attr == \"observations\":\n",
        "        continue\n",
        "      elif attr == \"terminations\":\n",
        "        ep[\"terminals\"] = value\n",
        "      elif attr == \"truncations\":\n",
        "        ep[\"timeouts\"] = value\n",
        "      elif attr == \"id\" or attr == \"seed\" or attr == \"total_timesteps\" or \"infos\"\n",
        "        continue\n",
        "      else:\n",
        "        ep[attr] = value\n",
        "\n",
        "    return ep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkYksqT8aY8d"
      },
      "outputs": [],
      "source": [
        "a = process_maze2d_episode(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcVb08Q4PTPG",
        "outputId": "c936ba38-1dc3-46b8-ebff-71d2ba710099"
      },
      "outputs": [],
      "source": [
        "print(a.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nxO9NIoTfrH",
        "outputId": "4b5b3977-db46-4e29-b86a-38cf6a6531b9"
      },
      "outputs": [],
      "source": [
        "a[\"terminals\"].any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvKzMJmf5nSP",
        "outputId": "a8fb30b5-c704-465d-e83a-2c02f22db903"
      },
      "outputs": [],
      "source": [
        "dataset[0].infos[\"goal\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8udmHX4-QPDR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JUQtkJu97Np",
        "outputId": "1cc825f3-90ab-4968-8ec4-dc08c2e94674"
      },
      "outputs": [],
      "source": [
        "for attr, value in vars(dataset[0]).items():\n",
        "    if attr == \"observations\":\n",
        "        continue\n",
        "    print(f\"{attr}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vatRKfTeUzKc",
        "outputId": "94502865-a78e-4180-dd1d-b2dd1d254fa7"
      },
      "outputs": [],
      "source": [
        "# dataset = get_dataset()\n",
        "# dataset = preprocess_fn(dataset)\n",
        "\n",
        "# N = dataset['rewards'].shape[0]\n",
        "N = dataset[0].rewards.shape[0]\n",
        "# N = dataset._data.total_episodes\n",
        "data_ = collections.defaultdict(list)\n",
        "\n",
        "# The newer version of the dataset adds an explicit\n",
        "# timeouts field. Keep old method for backwards compatability.\n",
        "use_timeouts = False\n",
        "print(N)\n",
        "episode_step = 0\n",
        "for i in range(N):\n",
        "    # print(dataset[i])\n",
        "    # dataset[i].observations\n",
        "    # done_bool = bool(dataset['terminals'][i])\n",
        "    done_bool = bool(dataset[episode_step].terminations[i])\n",
        "\n",
        "    final_timestep = episode_step == env._max_episode_steps - 1\n",
        "\n",
        "    # for k in dataset:\n",
        "    for attr, value in vars(dataset[episode_step]).items():\n",
        "        # if 'metadata' in k: continue\n",
        "        # data_[k].append(dataset[k][i])\n",
        "        data_[attr].append(value)\n",
        "\n",
        "    if done_bool or final_timestep:\n",
        "        episode_step = 0\n",
        "        episode_data = {}\n",
        "        for k in data_:\n",
        "            episode_data[k] = np.array(data_[k])\n",
        "        episode_data = process_maze2d_episode(dataset[i])\n",
        "        print(episode_data)\n",
        "        data_ = collections.defaultdict(list)\n",
        "\n",
        "        episode_step += 1\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yP4EZWUtjLEW",
        "Xh7nFzc5jxhB"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
