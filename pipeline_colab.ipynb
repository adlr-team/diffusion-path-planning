{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRAev-KUifbW",
        "outputId": "f70d8a10-4ddb-4bd6-8f38-cbc841993bb5"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "APRB2VcQU5C2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Beste Aydemir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\adlr-uQXv-DS1-py3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import gymnasium as gym\n",
        "from diffuser.utils.config import Config\n",
        "import os\n",
        "import collections\n",
        "import numpy as np\n",
        "import pdb\n",
        "from minari import DataCollector, StepDataCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Fd7E-bLXNI"
      },
      "source": [
        "## Diffuser Lib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rg9GmmXWStiK"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(\n",
        "        self,\n",
        "        loader,\n",
        "        savepath,\n",
        "        dataset,\n",
        "        horizon,\n",
        "        normalizer,\n",
        "        preprocess_fns,\n",
        "        use_padding,\n",
        "        max_path_length,\n",
        "        renderer,\n",
        "        model,\n",
        "        dim_mults,\n",
        "        device,\n",
        "    ):\n",
        "        self.loader = loader\n",
        "        self.savepath = savepath\n",
        "        self.dataset = dataset\n",
        "        self.horizon = horizon\n",
        "        self.normalizer = normalizer\n",
        "        self.preprocess_fns = preprocess_fns\n",
        "        self.use_padding = use_padding\n",
        "        self.max_path_length = max_path_length\n",
        "        self.renderer = renderer\n",
        "        self.model = model\n",
        "        # self.transition_dim=transition_dim\n",
        "        # self.cond_dim=cond_dim\n",
        "        self.dim_mults = dim_mults\n",
        "        self.device = device\n",
        "\n",
        "\n",
        "args = Args(\n",
        "    loader=\"datasets.sequence.GoalDataset\",\n",
        "    savepath=\"saved/\",\n",
        "    dataset=\"PointMaze_Medium-v3\",\n",
        "    horizon=256,\n",
        "    normalizer=\"LimitsNormalizer\",\n",
        "    preprocess_fns=[\"maze2d_set_terminals\"],\n",
        "    use_padding=False,\n",
        "    max_path_length=4000,\n",
        "    renderer=\"utils.rendering.Maze2dRenderer\",\n",
        "    model=\"models.temporal.TemporalUnet\",\n",
        "    dim_mults=(1, 4, 8),\n",
        "    device=\"cpu\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzUNVoCyS54w",
        "outputId": "8fd0ca8e-cce7-456b-9438-15ca2be74525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:datasets.sequence.GoalDataset\n",
            "[ utils/config ] Imported diffuser.datasets.sequence:GoalDataset\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.datasets.sequence.GoalDataset'>\n",
            "    env: PointMaze_Large-v3\n",
            "    horizon: 256\n",
            "    max_path_length: 4000\n",
            "    normalizer: LimitsNormalizer\n",
            "    preprocess_fns: ['maze2d_set_terminals']\n",
            "    use_padding: False\n",
            "\n",
            "[ utils/config ] Saved config to: saved/dataset_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataset_config = Config(\n",
        "    args.loader,\n",
        "    savepath=(args.savepath, \"dataset_config.pkl\"),\n",
        "    env=args.dataset,\n",
        "    horizon=args.horizon,\n",
        "    normalizer=args.normalizer,\n",
        "    preprocess_fns=args.preprocess_fns,\n",
        "    use_padding=args.use_padding,\n",
        "    max_path_length=args.max_path_length,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mminari\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollector, list_local_datasets, load_dataset, delete_dataset\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlist_local_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dataset_name)\n\u001b[0;32m      4\u001b[0m     delete_dataset(dataset_name)\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\adlr-uQXv-DS1-py3.10\\lib\\site-packages\\minari\\storage\\local.py:77\u001b[0m, in \u001b[0;36mlist_local_datasets\u001b[1;34m(latest_version, compatible_minari_version)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminari_version\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m metadata) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     73\u001b[0m     compatible_minari_version\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m __version__ \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SpecifierSet(metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminari_version\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     75\u001b[0m ):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m env_name, dataset_name, version \u001b[38;5;241m=\u001b[39m \u001b[43mparse_dataset_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdst_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m latest_version:\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\adlr-uQXv-DS1-py3.10\\lib\\site-packages\\minari\\dataset\\minari_dataset.py:45\u001b[0m, in \u001b[0;36mparse_dataset_id\u001b[1;34m(dataset_id)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mError(\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMalformed dataset ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. (Currently all IDs must be of the form (env_name-)(dataset_name)-v(version). (namespace is optional))\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m     )\n\u001b[0;32m     43\u001b[0m env_name, dataset_name, version \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m env_name, dataset_name, version\n",
            "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
          ]
        }
      ],
      "source": [
        "from minari import DataCollector, list_local_datasets, load_dataset, delete_dataset\n",
        "for dataset_name in list_local_datasets():\n",
        "    print(dataset_name)\n",
        "    delete_dataset(dataset_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN1wOeVGTaft",
        "outputId": "1d0e9bfe-1bca-4718-a6e9-03954dd5dbc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the enviornment: PointMaze_Large-v3\n",
            "Name of the enviornment: PointMaze_Large-v3\n",
            "Dataset_name:pointmaze-umaze-v0\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "int() argument must be a string, a bytes-like object or a real number, not 'NoneType'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\diffuser-third-test\\diffuser\\utils\\config.py:71\u001b[0m, in \u001b[0;36mConfig.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 71\u001b[0m     instance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;66;03m# if self._device:\u001b[39;00m\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;66;03m#     instance = instance.to(self._device)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m instance\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\diffuser-third-test\\diffuser\\datasets\\sequence.py:30\u001b[0m, in \u001b[0;36mSequenceDataset.__init__\u001b[1;34m(self, env, horizon, normalizer, preprocess_fns, max_path_length, max_n_episodes, termination_penalty, use_padding, seed)\u001b[0m\n\u001b[0;32m     27\u001b[0m itr \u001b[38;5;241m=\u001b[39m sequence_dataset(env, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_fn)\n\u001b[0;32m     29\u001b[0m fields \u001b[38;5;241m=\u001b[39m ReplayBuffer(max_n_episodes, max_path_length, termination_penalty)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, episode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(itr):\n\u001b[0;32m     31\u001b[0m     fields\u001b[38;5;241m.\u001b[39madd_path(episode)\n\u001b[0;32m     32\u001b[0m fields\u001b[38;5;241m.\u001b[39mfinalize()\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\diffuser-third-test\\diffuser\\datasets\\d4rl.py:219\u001b[0m, in \u001b[0;36msequence_dataset\u001b[1;34m(env, preprocess_fn)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msequence_dataset\u001b[39m(env, preprocess_fn):\n\u001b[0;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    Returns an iterator through trajectories.\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;124;03m            terminals\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m preprocess_fn(dataset)\n\u001b[0;32m    222\u001b[0m     N \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\diffuser-third-test\\diffuser\\datasets\\d4rl.py:63\u001b[0m, in \u001b[0;36mget_dataset\u001b[1;34m()\u001b[0m\n\u001b[0;32m     58\u001b[0m env \u001b[38;5;241m=\u001b[39m gym\u001b[38;5;241m.\u001b[39mmake(\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPointMaze_Medium-v3\u001b[39m\u001b[38;5;124m\"\u001b[39m, continuing_task\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_episode_steps\u001b[38;5;241m=\u001b[39mtotal_steps\n\u001b[0;32m     60\u001b[0m )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Load exisiting datasets:\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlist_local_datasets\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset exists!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m load_dataset(dataset_name)\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\adlr-uQXv-DS1-py3.10\\lib\\site-packages\\minari\\storage\\local.py:77\u001b[0m, in \u001b[0;36mlist_local_datasets\u001b[1;34m(latest_version, compatible_minari_version)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminari_version\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m metadata) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m     73\u001b[0m     compatible_minari_version\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m __version__ \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SpecifierSet(metadata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminari_version\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     75\u001b[0m ):\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m env_name, dataset_name, version \u001b[38;5;241m=\u001b[39m \u001b[43mparse_dataset_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdst_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m latest_version:\n",
            "File \u001b[1;32mc:\\Users\\Beste Aydemir\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\adlr-uQXv-DS1-py3.10\\lib\\site-packages\\minari\\dataset\\minari_dataset.py:45\u001b[0m, in \u001b[0;36mparse_dataset_id\u001b[1;34m(dataset_id)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mError(\n\u001b[0;32m     41\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMalformed dataset ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. (Currently all IDs must be of the form (env_name-)(dataset_name)-v(version). (namespace is optional))\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     42\u001b[0m     )\n\u001b[0;32m     43\u001b[0m env_name, dataset_name, version \u001b[38;5;241m=\u001b[39m match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menvironment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m env_name, dataset_name, version\n",
            "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'"
          ]
        }
      ],
      "source": [
        "dataset = dataset_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvk2JJzc6BO6",
        "outputId": "89b725cd-4487-4716-e55f-9b346b7e4e95"
      },
      "outputs": [],
      "source": [
        "# dataset[1]\n",
        "# dataset[1].observations[\"observation\"][:, :2]\n",
        "# dataset[1].total_steps\n",
        "# env = gym.make(\"PointMaze_Large-v3\")\n",
        "# env._max_episode_steps\n",
        "# # env.target\n",
        "# np.array(wrapped_env.observation_space[\"desired_goal\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENDornlpjRvY"
      },
      "source": [
        "## Configs for Rendering and the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bme6emjGVS6-",
        "outputId": "847b6b49-3758-4e5a-9e0c-3e3872f65259"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:utils.rendering.Maze2dRenderer\n",
            "[ utils/config ] Imported diffuser.utils.rendering:Maze2dRenderer\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.utils.rendering.Maze2dRenderer'>\n",
            "    env: PointMaze_Large-v3\n",
            "\n",
            "[ utils/config ] Saved config to: saved/render_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "render_config = Config(\n",
        "    args.renderer,\n",
        "    savepath=(args.savepath, \"render_config.pkl\"),\n",
        "    env=args.dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtDYVRdctm86",
        "outputId": "3c4a10d7-ccde-41d4-f7cf-19404180f063"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:models.temporal.TemporalUnet\n",
            "[ utils/config ] Imported diffuser.models.temporal:TemporalUnet\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.models.temporal.TemporalUnet'>\n",
            "    cond_dim: 4\n",
            "    dim_mults: (1, 4, 8)\n",
            "    horizon: 256\n",
            "    transition_dim: 6\n",
            "\n",
            "[ utils/config ] Saved config to: saved/model_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# observation_dim = dataset.observation_dim\n",
        "# action_dim = dataset.action_dim\n",
        "observation_dim = 4\n",
        "action_dim = 2\n",
        "# -----------------------------------------------------------------------------#\n",
        "# ------------------------------ model & trainer ------------------------------#\n",
        "# -----------------------------------------------------------------------------#\n",
        "\n",
        "model_config = Config(\n",
        "    args.model,\n",
        "    savepath=(args.savepath, \"model_config.pkl\"),\n",
        "    horizon=args.horizon,\n",
        "    transition_dim=observation_dim + action_dim,\n",
        "    cond_dim=observation_dim,\n",
        "    dim_mults=args.dim_mults,\n",
        "    device=args.device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLILqE_ZrBdy",
        "outputId": "2a032e3e-bf83-48a1-f186-e1c5a62a5e3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name of the enviornment: PointMaze_Large-v3\n"
          ]
        }
      ],
      "source": [
        "renderer = render_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0362NXnEtqzJ",
        "outputId": "b3be0703-1e9a-4fb4-fba6-bc14a3052215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ models/temporal ] Channel dimensions: [(6, 32), (32, 128), (128, 256)]\n",
            "[(6, 32), (32, 128), (128, 256)]\n"
          ]
        }
      ],
      "source": [
        "model = model_config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56UTrirwtof5",
        "outputId": "a0d92bcc-c4f6-41bd-fa4f-54d7887afa4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_class:models.diffuser.GaussianDiffusion\n",
            "[ utils/config ] Imported diffuser.models.diffuser:GaussianDiffusion\n",
            "\n",
            "[utils/config ] Config: <class 'diffuser.models.diffuser.GaussianDiffusion'>\n",
            "    action_dim: 2\n",
            "    action_weight: 1\n",
            "    clip_denoised: True\n",
            "    horizon: 256\n",
            "    loss_discount: 1\n",
            "    loss_type: l2\n",
            "    loss_weights: None\n",
            "    n_timesteps: 256\n",
            "    observation_dim: 4\n",
            "    predict_epsilon: False\n",
            "\n",
            "[ utils/config ] Saved config to: saved/diffusion_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "diffusion_config = Config(\n",
        "    _class=\"models.diffuser.GaussianDiffusion\",\n",
        "    savepath=(args.savepath, \"diffusion_config.pkl\"),\n",
        "    horizon=256,\n",
        "    observation_dim=observation_dim,\n",
        "    action_dim=2,\n",
        "    n_timesteps=256,\n",
        "    loss_type=\"l2\",\n",
        "    clip_denoised=True,\n",
        "    predict_epsilon=False,\n",
        "    # loss weighting\n",
        "    action_weight=1,\n",
        "    loss_weights=None,\n",
        "    loss_discount=1,\n",
        "    device=args.device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUBUMLX-KX-D"
      },
      "outputs": [],
      "source": [
        "diffuser = diffusion_config(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcJZFQl9jXtn"
      },
      "source": [
        "## Forward pass is working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SnQpWsjKlRQ",
        "outputId": "6c4ce3f1-c507-42e2-e51b-485e83ed51ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ utils/arrays ] Total parameters: 3.68 M\n",
            "         downs.2.0.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.2.1.blocks.0.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.2.1.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         ups.0.0.blocks.0.block.0.weight: 327.68 k | Conv1d(512, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block1.blocks.0.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block1.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block2.blocks.0.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         mid_block2.blocks.1.block.0.weight: 327.68 k | Conv1d(256, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.2.0.blocks.0.block.0.weight: 163.84 k | Conv1d(128, 256, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         downs.1.0.blocks.1.block.0.weight: 81.92 k | Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
            "         ... and 138 others accounting for 814.92 k parameters\n",
            "Testing forward... "
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m report_parameters(model)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting forward...\u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 6\u001b[0m batch \u001b[38;5;241m=\u001b[39m batchify(\u001b[43mdataset\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      7\u001b[0m loss, _ \u001b[38;5;241m=\u001b[39m diffuser\u001b[38;5;241m.\u001b[39mloss(\u001b[38;5;241m*\u001b[39mbatch)\n\u001b[0;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "from diffuser.utils.arrays import report_parameters, batchify\n",
        "\n",
        "report_parameters(model)\n",
        "\n",
        "print(\"Testing forward...\", end=\" \", flush=True)\n",
        "batch = batchify(dataset[0])\n",
        "loss, _ = diffuser.loss(*batch)\n",
        "loss.backward()\n",
        "print(\"âœ“\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2zObsfx8uFq"
      },
      "source": [
        "## Using the trainer requires taking care of the 'device' in the folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4Ahsw3rhEeF",
        "outputId": "72015822-2ea3-4d8d-df37-76026af74d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[utils/config ] Config: <class 'diffuser.utils.training.Trainer'>\n",
            "    bucket: None\n",
            "    ema_decay: 0.005\n",
            "    gradient_accumulate_every: 2\n",
            "    label_freq: 400\n",
            "    n_reference: 1\n",
            "    n_samples: 1\n",
            "    results_folder: saved/\n",
            "    sample_freq: 1000\n",
            "    save_freq: 1000\n",
            "    save_parallel: False\n",
            "    train_batch_size: 32\n",
            "    train_lr: 0.0002\n",
            "\n",
            "[ utils/config ] Saved config to: saved/trainer_config.pkl\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from diffuser.utils.training import Trainer\n",
        "\n",
        "trainer_config = Config(\n",
        "    Trainer,\n",
        "    savepath=(args.savepath, \"trainer_config.pkl\"),\n",
        "    train_batch_size=32,\n",
        "    train_lr=2e-4,\n",
        "    gradient_accumulate_every=2,\n",
        "    ema_decay=0.005,\n",
        "    sample_freq=1000,\n",
        "    save_freq=1000,\n",
        "    label_freq=int(2e4 // 50),\n",
        "    save_parallel=False,\n",
        "    results_folder=args.savepath,\n",
        "    bucket=None,\n",
        "    n_reference=1,\n",
        "    n_samples=1,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KcB-OnzvkFgn"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m trainer_config(diffuser, \u001b[43mdataset\u001b[49m, renderer)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "trainer = trainer_config(diffuser, dataset, renderer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRJlcy_WKXdq"
      },
      "source": [
        "# Training process inlcluding rendering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "IaDt0qR3kczo",
        "outputId": "1ac1ee61-695b-4017-cd62-41bf7449b7b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 / 1 | saved/\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'trainer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_epochs):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;241m.\u001b[39msavepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mtrain(n_train_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'trainer' is not defined"
          ]
        }
      ],
      "source": [
        "# n_epochs = int(args.n_train_steps // args.n_steps_per_epoch)\n",
        "n_epochs = 1\n",
        "for i in range(n_epochs):\n",
        "    print(f\"Epoch {i} / {n_epochs} | {args.savepath}\")\n",
        "    trainer.train(n_train_steps=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh7nFzc5jxhB"
      },
      "source": [
        "## Random Test (don't run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDUP3qKtE5Kw",
        "outputId": "518943ce-53b7-483f-c3bf-b73305daee0b"
      },
      "outputs": [],
      "source": [
        "from contextlib import (\n",
        "    contextmanager,\n",
        "    redirect_stderr,\n",
        "    redirect_stdout,\n",
        ")\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def suppress_output():\n",
        "    \"\"\"\n",
        "    A context manager that redirects stdout and stderr to devnull\n",
        "    https://stackoverflow.com/a/52442331\n",
        "    \"\"\"\n",
        "    with open(os.devnull, \"w\") as fnull:\n",
        "        with redirect_stderr(fnull) as err, redirect_stdout(fnull) as out:\n",
        "            yield (err, out)\n",
        "\n",
        "\n",
        "# with suppress_output():\n",
        "#     ## d4rl prints out a variety of warnings\n",
        "#     import d4rl\n",
        "\n",
        "# -----------------------------------------------------------------------------#\n",
        "# -------------------------------- general api --------------------------------#\n",
        "# -----------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "def load_environment(name):\n",
        "    print(name)\n",
        "    if type(name) != str:\n",
        "        # name is already an environment\n",
        "        return name\n",
        "    with suppress_output():\n",
        "        wrapped_env = gym.make(name)\n",
        "    env = wrapped_env.unwrapped\n",
        "    env.max_episode_steps = wrapped_env._max_episode_steps\n",
        "    env.name = name\n",
        "    return env\n",
        "\n",
        "\n",
        "class PointMazeStepDataCallback(StepDataCallback):\n",
        "    \"\"\"Add environment state information to 'infos'.\n",
        "\n",
        "    Also, since the environment generates a new target every time it reaches a goal, the environment is\n",
        "    never terminated or truncated. This callback overrides the truncation value to True when the step\n",
        "    returns a True 'succes' key in 'infos'. This way we can divide the Minari dataset into different trajectories.\n",
        "    \"\"\"\n",
        "\n",
        "    def __call__(\n",
        "        self, env, obs, info, action=None, rew=None, terminated=None, truncated=None\n",
        "    ):\n",
        "        qpos = obs[\"observation\"][:2]\n",
        "        qvel = obs[\"observation\"][2:]\n",
        "        goal = obs[\"desired_goal\"]\n",
        "\n",
        "        step_data = super().__call__(env, obs, info, action, rew, terminated, truncated)\n",
        "\n",
        "        if step_data[\"infos\"][\"success\"]:\n",
        "            step_data[\"truncation\"] = True\n",
        "        step_data[\"infos\"][\"qpos\"] = qpos\n",
        "        step_data[\"infos\"][\"qvel\"] = qvel\n",
        "        step_data[\"infos\"][\"goal\"] = goal\n",
        "\n",
        "        return step_data\n",
        "\n",
        "\n",
        "UP = 0\n",
        "DOWN = 1\n",
        "LEFT = 2\n",
        "RIGHT = 3\n",
        "\n",
        "EXPLORATION_ACTIONS = {UP: (0, 1), DOWN: (0, -1), LEFT: (-1, 0), RIGHT: (1, 0)}\n",
        "\n",
        "\n",
        "class QIteration:\n",
        "    \"\"\"Solves for optimal policy with Q-Value Iteration.\n",
        "\n",
        "    Inspired by https://github.com/Farama-Foundation/D4RL/blob/master/d4rl/pointmaze/q_iteration.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, maze):\n",
        "        self.maze = maze\n",
        "        self.num_states = maze.map_length * maze.map_width\n",
        "        self.num_actions = len(EXPLORATION_ACTIONS.keys())\n",
        "        self.rew_matrix = np.zeros((self.num_states, self.num_actions))\n",
        "        self.compute_transition_matrix()\n",
        "\n",
        "    def generate_path(self, current_cell, goal_cell):\n",
        "        self.compute_reward_matrix(goal_cell)\n",
        "        q_values = self.get_q_values()\n",
        "        current_state = self.cell_to_state(current_cell)\n",
        "        waypoints = {}\n",
        "        while True:\n",
        "            action_id = np.argmax(q_values[current_state])\n",
        "            next_state, _ = self.get_next_state(\n",
        "                current_state, EXPLORATION_ACTIONS[action_id]\n",
        "            )\n",
        "            current_cell = self.state_to_cell(current_state)\n",
        "            waypoints[current_cell] = self.state_to_cell(next_state)\n",
        "            if waypoints[current_cell] == goal_cell:\n",
        "                break\n",
        "\n",
        "            current_state = next_state\n",
        "\n",
        "        return waypoints\n",
        "\n",
        "    def reward_function(self, desired_cell, current_cell):\n",
        "        if desired_cell == current_cell:\n",
        "            return 1.0\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "    def state_to_cell(self, state):\n",
        "        i = int(state / self.maze.map_width)\n",
        "        j = state % self.maze.map_width\n",
        "        return (i, j)\n",
        "\n",
        "    def cell_to_state(self, cell):\n",
        "        return cell[0] * self.maze.map_width + cell[1]\n",
        "\n",
        "    def get_q_values(self, num_itrs=50, discount=0.99):\n",
        "        q_fn = np.zeros((self.num_states, self.num_actions))\n",
        "        for _ in range(num_itrs):\n",
        "            v_fn = np.max(q_fn, axis=1)\n",
        "            q_fn = self.rew_matrix + discount * self.transition_matrix.dot(v_fn)\n",
        "        return q_fn\n",
        "\n",
        "    def compute_reward_matrix(self, goal_cell):\n",
        "        for state in range(self.num_states):\n",
        "            for action in range(self.num_actions):\n",
        "                next_state, _ = self.get_next_state(state, EXPLORATION_ACTIONS[action])\n",
        "                next_cell = self.state_to_cell(next_state)\n",
        "                self.rew_matrix[state, action] = self.reward_function(\n",
        "                    goal_cell, next_cell\n",
        "                )\n",
        "\n",
        "    def compute_transition_matrix(self):\n",
        "        \"\"\"Constructs this environment's transition matrix.\n",
        "        Returns:\n",
        "          A dS x dA x dS array where the entry transition_matrix[s, a, ns]\n",
        "          corresponds to the probability of transitioning into state ns after taking\n",
        "          action a from state s.\n",
        "        \"\"\"\n",
        "        self.transition_matrix = np.zeros(\n",
        "            (self.num_states, self.num_actions, self.num_states)\n",
        "        )\n",
        "        for state in range(self.num_states):\n",
        "            for action_idx, action in EXPLORATION_ACTIONS.items():\n",
        "                next_state, valid = self.get_next_state(state, action)\n",
        "                if valid:\n",
        "                    self.transition_matrix[state, action_idx, next_state] = 1\n",
        "\n",
        "    def get_next_state(self, state, action):\n",
        "        cell = self.state_to_cell(state)\n",
        "\n",
        "        next_cell = tuple(map(lambda i, j: int(i + j), cell, action))\n",
        "        next_state = self.cell_to_state(next_cell)\n",
        "\n",
        "        return next_state, self._check_valid_cell(next_cell)\n",
        "\n",
        "    def _check_valid_cell(self, cell):\n",
        "        # Out of map bounds\n",
        "        if cell[0] >= self.maze.map_length:\n",
        "            return False\n",
        "        elif cell[1] >= self.maze.map_width:\n",
        "            return False\n",
        "        # Wall collision\n",
        "        elif self.maze.maze_map[cell[0]][cell[1]] == 1:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "\n",
        "class WaypointController:\n",
        "    \"\"\"Agent controller to follow waypoints in the maze.\n",
        "\n",
        "    Inspired by https://github.com/Farama-Foundation/D4RL/blob/master/d4rl/pointmaze/waypoint_controller.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, maze, gains={\"p\": 10.0, \"d\": -1.0}, waypoint_threshold=0.1):\n",
        "        self.global_target_xy = np.empty(2)\n",
        "        self.maze = maze\n",
        "\n",
        "        self.maze_solver = QIteration(maze=self.maze)\n",
        "\n",
        "        self.gains = gains\n",
        "        self.waypoint_threshold = waypoint_threshold\n",
        "        self.waypoint_targets = None\n",
        "\n",
        "    def compute_action(self, obs):\n",
        "        # Check if we need to generate new waypoint path due to change in global target\n",
        "        if (\n",
        "            np.linalg.norm(self.global_target_xy - obs[\"desired_goal\"]) > 1e-3\n",
        "            or self.waypoint_targets is None\n",
        "        ):\n",
        "            # Convert xy to cell id\n",
        "            achieved_goal_cell = tuple(\n",
        "                self.maze.cell_xy_to_rowcol(obs[\"achieved_goal\"])\n",
        "            )\n",
        "            self.global_target_id = tuple(\n",
        "                self.maze.cell_xy_to_rowcol(obs[\"desired_goal\"])\n",
        "            )\n",
        "            self.global_target_xy = obs[\"desired_goal\"]\n",
        "\n",
        "            self.waypoint_targets = self.maze_solver.generate_path(\n",
        "                achieved_goal_cell, self.global_target_id\n",
        "            )\n",
        "\n",
        "            # Check if the waypoint dictionary is empty\n",
        "            # If empty then the ball is already in the target cell location\n",
        "            if self.waypoint_targets:\n",
        "                self.current_control_target_id = self.waypoint_targets[\n",
        "                    achieved_goal_cell\n",
        "                ]\n",
        "                self.current_control_target_xy = self.maze.cell_rowcol_to_xy(\n",
        "                    np.array(self.current_control_target_id)\n",
        "                )\n",
        "            else:\n",
        "                self.waypoint_targets[self.current_control_target_id] = (\n",
        "                    self.current_control_target_id\n",
        "                )\n",
        "                self.current_control_target_id = self.global_target_id\n",
        "                self.current_control_target_xy = self.global_target_xy\n",
        "\n",
        "        # Check if we need to go to the next waypoint\n",
        "        dist = np.linalg.norm(self.current_control_target_xy - obs[\"achieved_goal\"])\n",
        "        if (\n",
        "            dist <= self.waypoint_threshold\n",
        "            and self.current_control_target_id != self.global_target_id\n",
        "        ):\n",
        "            self.current_control_target_id = self.waypoint_targets[\n",
        "                self.current_control_target_id\n",
        "            ]\n",
        "            # If target is global goal go directly to goal position\n",
        "            if self.current_control_target_id == self.global_target_id:\n",
        "                self.current_control_target_xy = self.global_target_xy\n",
        "            else:\n",
        "                self.current_control_target_xy = (\n",
        "                    self.maze.cell_rowcol_to_xy(\n",
        "                        np.array(self.current_control_target_id)\n",
        "                    )\n",
        "                    - np.random.uniform(size=(2,)) * 0.2\n",
        "                )\n",
        "\n",
        "        action = (\n",
        "            self.gains[\"p\"] * (self.current_control_target_xy - obs[\"achieved_goal\"])\n",
        "            + self.gains[\"d\"] * obs[\"observation\"][2:]\n",
        "        )\n",
        "        action = np.clip(action, -1, 1)\n",
        "\n",
        "        return action\n",
        "\n",
        "\n",
        "def get_dataset():\n",
        "    # Code from Minari documentation\n",
        "    dataset_name = \"pointmaze-umaze-v0\"\n",
        "    total_steps = 20_000\n",
        "\n",
        "    # continuing task => the episode doesn't terminate or truncate when reaching a goal\n",
        "    # it will generate a new target. For this reason we set the maximum episode steps to\n",
        "    # the desired size of our Minari dataset (evade truncation due to time limit)\n",
        "    env = gym.make(\n",
        "        \"PointMaze_Medium-v3\", continuing_task=True, max_episode_steps=total_steps // 2\n",
        "    )\n",
        "\n",
        "    # Data collector wrapper to save temporary data while stepping. Characteristics:\n",
        "    #   * Custom StepDataCallback to add extra state information to 'infos' and divide dataset in different episodes by overridng\n",
        "    #     truncation value to True when target is reached\n",
        "    #   * Record the 'info' value of every step\n",
        "    collector_env = DataCollector(\n",
        "        env, step_data_callback=PointMazeStepDataCallback, record_infos=True\n",
        "    )\n",
        "\n",
        "    obs, _ = collector_env.reset(seed=123)\n",
        "\n",
        "    waypoint_controller = WaypointController(maze=env.maze)\n",
        "\n",
        "    for n_step in range(int(total_steps)):\n",
        "        action = waypoint_controller.compute_action(obs)\n",
        "        # Add some noise to each step action\n",
        "        action += np.random.randn(*action.shape) * 0.5\n",
        "        action = np.clip(\n",
        "            action, env.action_space.low, env.action_space.high, dtype=np.float32\n",
        "        )\n",
        "\n",
        "        obs, rew, terminated, truncated, info = collector_env.step(action)\n",
        "\n",
        "    dataset = collector_env.create_dataset(\n",
        "        dataset_id=dataset_name,\n",
        "        algorithm_name=\"QIteration\",\n",
        "        code_permalink=\"https://github.com/Farama-Foundation/Minari/blob/main/docs/tutorials/dataset_creation/point_maze_dataset.py\",\n",
        "        author=\"Rodrigo Perez-Vicente\",\n",
        "        author_email=\"rperezvicente@farama.org\",\n",
        "    )\n",
        "    return dataset\n",
        "\n",
        "\n",
        "dataset = get_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "Qb0DuGNZQMbE",
        "outputId": "2dbcd2a9-9641-4daa-92bb-956bc8a03754"
      },
      "outputs": [],
      "source": [
        "print(dataset)\n",
        "print(dataset[\"actions\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "vugWLtYdZedT",
        "outputId": "12030896-dac2-4e04-f7c9-751cf3f9d8b1"
      },
      "outputs": [],
      "source": [
        "reshaped = {}\n",
        "for key, val in dataset.items():\n",
        "    dim = val.shape[-1]\n",
        "    reshaped[key] = val.reshape(-1, dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVkGiVc-ZFf_"
      },
      "outputs": [],
      "source": [
        "def process_maze2d_episode(episode):\n",
        "    '''\n",
        "        adds in `next_observations` field to episode\n",
        "    '''\n",
        "    #assert 'next_observations' not in episode\n",
        "    ep = {}\n",
        "    length = len(episode.observations)\n",
        "    next_observations = episode.observations[\"observation\"][1:].copy()\n",
        "    for key, val in episode.observations.items():\n",
        "        ep[key] = val[:-1]\n",
        "    ep['next_observations'] = next_observations\n",
        "    for attr, value in vars(episode).items():\n",
        "      if attr == \"observations\":\n",
        "        continue\n",
        "      elif attr == \"terminations\":\n",
        "        ep[\"terminals\"] = value\n",
        "      elif attr == \"truncations\":\n",
        "        ep[\"timeouts\"] = value\n",
        "      elif attr == \"id\" or attr == \"seed\" or attr == \"total_timesteps\" or \"infos\"\n",
        "        continue\n",
        "      else:\n",
        "        ep[attr] = value\n",
        "\n",
        "    return ep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GkYksqT8aY8d"
      },
      "outputs": [],
      "source": [
        "a = process_maze2d_episode(dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcVb08Q4PTPG",
        "outputId": "c936ba38-1dc3-46b8-ebff-71d2ba710099"
      },
      "outputs": [],
      "source": [
        "print(a.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7nxO9NIoTfrH",
        "outputId": "4b5b3977-db46-4e29-b86a-38cf6a6531b9"
      },
      "outputs": [],
      "source": [
        "a[\"terminals\"].any()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvKzMJmf5nSP",
        "outputId": "a8fb30b5-c704-465d-e83a-2c02f22db903"
      },
      "outputs": [],
      "source": [
        "dataset[0].infos[\"goal\"].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8udmHX4-QPDR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JUQtkJu97Np",
        "outputId": "1cc825f3-90ab-4968-8ec4-dc08c2e94674"
      },
      "outputs": [],
      "source": [
        "for attr, value in vars(dataset[0]).items():\n",
        "    if attr == \"observations\":\n",
        "        continue\n",
        "    print(f\"{attr}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vatRKfTeUzKc",
        "outputId": "94502865-a78e-4180-dd1d-b2dd1d254fa7"
      },
      "outputs": [],
      "source": [
        "# dataset = get_dataset()\n",
        "# dataset = preprocess_fn(dataset)\n",
        "\n",
        "# N = dataset['rewards'].shape[0]\n",
        "N = dataset[0].rewards.shape[0]\n",
        "# N = dataset._data.total_episodes\n",
        "data_ = collections.defaultdict(list)\n",
        "\n",
        "# The newer version of the dataset adds an explicit\n",
        "# timeouts field. Keep old method for backwards compatability.\n",
        "use_timeouts = False\n",
        "print(N)\n",
        "episode_step = 0\n",
        "for i in range(N):\n",
        "    # print(dataset[i])\n",
        "    # dataset[i].observations\n",
        "    # done_bool = bool(dataset['terminals'][i])\n",
        "    done_bool = bool(dataset[episode_step].terminations[i])\n",
        "\n",
        "    final_timestep = episode_step == env._max_episode_steps - 1\n",
        "\n",
        "    # for k in dataset:\n",
        "    for attr, value in vars(dataset[episode_step]).items():\n",
        "        # if 'metadata' in k: continue\n",
        "        # data_[k].append(dataset[k][i])\n",
        "        data_[attr].append(value)\n",
        "\n",
        "    if done_bool or final_timestep:\n",
        "        episode_step = 0\n",
        "        episode_data = {}\n",
        "        for k in data_:\n",
        "            episode_data[k] = np.array(data_[k])\n",
        "        episode_data = process_maze2d_episode(dataset[i])\n",
        "        print(episode_data)\n",
        "        data_ = collections.defaultdict(list)\n",
        "\n",
        "        episode_step += 1\n",
        "    break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "yP4EZWUtjLEW",
        "Xh7nFzc5jxhB"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
